{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a20bcb-9fdf-4b0a-993c-19719e03f886",
   "metadata": {},
   "source": [
    "#### COCO JSON 파일을 사용하여 학습 시점에 즉석에서 마스크를 생성\n",
    "\n",
    "별도의 마스크 이미지 파일 없이 원본 이미지와 JSON 파일만 있으면 동작하며, \n",
    "Lanemark와 같은 중요 클래스에 가중치를 두어 성능을 높이도록 설계됨. \n",
    "\n",
    "사전 준비\n",
    "```\n",
    "$ pip install pycocotools\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46839347-e619-4a0b-baa9-8bd1283f634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de841dc5-a7ca-44b5-9ce8-6893af58ea16",
   "metadata": {},
   "source": [
    "1. COCO JSON 기반의 커스텀 데이터셋 정의\n",
    "* 데이터를 로드, 전처리\n",
    "\t* cat_id_to_index 매핑: \n",
    "\t\t* COCO JSON의 카테고리 ID는 보통 불연속적(예: 1, 15, 23)입니다. \n",
    "\t\t* 이를 신경망 학습에 적합하도록 0, 1, 2... 형태의 연속적인 인덱스로 변환합니다.\n",
    "\t* On-the-fly 마스크 생성: \n",
    "\t\t* coco.annToMask(ann) 함수를 사용하여 JSON의 폴리곤 좌표 데이터를 픽셀 형태의 이진 마스크로 바꾼 뒤, 해당 클래스 번호를 할당합니다.\n",
    "\t* 보간법(Interpolation) 처리:\n",
    "\t\t* 이미지 크기를 조절할 때는 일반적인 보간법을 쓰지만, 마스크(정답)의 경우 값이 뭉개지면 안 되므로 반드시 NEAREST (최근접 이웃) 보간법을 사용합니다。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53181c3f-8acd-40f3-8b08-a1531725c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotorcycleCocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, ann_file, transform=None, num_classes=6):\n",
    "        self.img_dir = img_dir\n",
    "        self.coco = COCO(ann_file) # JSON 파일 로드\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # 카테고리 id들을 0..N-1 인덱스로 매핑\n",
    "        self.cat_ids = sorted(self.coco.getCatIds())\n",
    "        cats = self.coco.loadCats(self.cat_ids)\n",
    "        # map original category_id -> continuous index (0..)\n",
    "        self.cat_id_to_index = {cat['id']: idx for idx, cat in enumerate(cats)}\n",
    "        if len(self.cat_id_to_index) > self.num_classes:\n",
    "            raise ValueError(f\"Found {len(self.cat_id_to_index)} categories but num_classes={self.num_classes}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        \n",
    "        # 이미지 로드\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        # 이미지 로드 (안전하게 리스트 인자로 전달)\n",
    "        img_info = coco.loadImgs([img_id])[0]\n",
    "        try:\n",
    "            img = Image.open(os.path.join(self.img_dir, img_info['file_name'])).convert('RGB')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load image {img_info.get('file_name')} : {e}\")\n",
    "\n",
    "        # JSON의 폴리곤 좌표를 사용하여 픽셀 마스크 생성\n",
    "        mask = np.zeros((img.height, img.width), dtype=np.uint8)\n",
    "        for ann in anns:\n",
    "            kind_mask = coco.annToMask(ann).astype(bool)\n",
    "            cat_id = ann.get('category_id')\n",
    "            mapped = self.cat_id_to_index.get(cat_id)\n",
    "            if mapped is None:\n",
    "                # unknown category -> skip (treated as background)\n",
    "                continue\n",
    "            mask[kind_mask] = mapped\n",
    "\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            # 마스크는 보간법 없이 크기만 조정\n",
    "            mask = transforms.Resize((256, 256), interpolation=Image.NEAREST)(mask)\n",
    "            mask = torch.from_numpy(np.array(mask)).long()\n",
    "        else:\n",
    "            mask = torch.from_numpy(np.array(mask)).long()\n",
    "\n",
    "        # 안전 검사: 레이블 값이 허용 범위 내인지 확인\n",
    "        if mask.max() >= self.num_classes:\n",
    "            raise ValueError(f\"Mask label {int(mask.max())} >= num_classes ({self.num_classes})\")\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2652fc2-c8b3-4ac9-82a7-329ecc8a7d95",
   "metadata": {},
   "source": [
    "2. get_criterion 함수 (가중치 기반 손실 함수)\n",
    "  * 세그멘테이션 데이터셋의 고질적인 문제인 클래스 불균형을 해결하기 위한 전략\n",
    "  * 클래스별 가중치: 배경(1.0)이나 도로(1.0)에 비해 픽셀 면적이 좁고 중요한 차선(Lanemark, 8.0)과 이동 물체(Movable, 4.0)에 높은 가중치를 부여한다. \n",
    "  * 이렇게 하면 모델이 차선처럼 작은 영역을 틀렸을 때 훨씬 큰 벌칙(Loss)을 받아 해당 부분을 더 집중해서 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a6981f-16fb-4ec1-9d7a-8e0881a9b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(device):\n",
    "    # 야간 주행 시 식별이 어려운 Lanemark(차선) 등에 높은 가중치 부여 [cite: 17, 23]\n",
    "    # 순서: [Background/Undrivable, Lanemark, Road, Movable, My bike, Rider]\n",
    "    weights = torch.tensor([1.0, 8.0, 1.0, 4.0, 2.0, 2.0], dtype=torch.float).to(device)\n",
    "    return nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bdde2a-4f22-4eb2-b236-627a0fd34965",
   "metadata": {},
   "source": [
    "3. 메인 학습 루프\n",
    "\t* DeepLabV3 ResNet50: 구글이 개발한 고성능 세그멘테이션 모델\n",
    "\t* Optimizer: 보편적으로 성능이 좋은 Adam을 선택했습니다.\n",
    "\t* 데이터 흐름: Batch Size 4로 이미지를 입력받아 6개 클래스에 대한 예측 맵을 생성하고, 실제 마스크와 비교하여 가중치가 적용된 CrossEntropyLoss를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683e6095-bde2-4498-8c00-812faa4bde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # 재현성 설정\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "    # 데이터 설정 (이미지 200프레임 기반) [cite: 8]\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 경로 설정 (실제 경로에 맞게 수정)\n",
    "    dataset = MotorcycleCocoDataset(\n",
    "        img_dir='./data/images', \n",
    "        ann_file='./data/annotations.json', \n",
    "        transform=data_transform\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "    \n",
    "    # 모델: DeepLabV3 ResNet50 (6개 클래스 분류용)\n",
    "    # torchvision API differs by version; try common signatures\n",
    "    try:\n",
    "        model = models.segmentation.deeplabv3_resnet50(weights=None, num_classes=6).to(device)\n",
    "    except TypeError:\n",
    "        model = models.segmentation.deeplabv3_resnet50(pretrained=False, num_classes=6).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = get_criterion(device)\n",
    "\n",
    "    print(\"Start Trainning ...\")\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for imgs, masks in dataloader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            \n",
    "            outputs = model(imgs)['out']\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}: Loss = {epoch_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e9dab1-11ee-431e-9c1d-efcf6c05f8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 138MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Trainning ...\n",
      "Epoch 1: Loss = 0.6496\n",
      "Epoch 2: Loss = 0.2991\n",
      "Epoch 3: Loss = 0.2238\n",
      "Epoch 4: Loss = 0.1894\n",
      "Epoch 5: Loss = 0.1695\n",
      "Epoch 6: Loss = 0.1515\n",
      "Epoch 7: Loss = 0.1369\n",
      "Epoch 8: Loss = 0.1255\n",
      "Epoch 9: Loss = 0.1212\n",
      "Epoch 10: Loss = 0.1132\n"
     ]
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
