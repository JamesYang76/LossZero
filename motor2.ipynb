{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ğŸï¸ LossZero: Motorcycle Night Ride SegFormer-B2 Optimized\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **SegFormer-B2** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•¼ê°„ ì˜¤í† ë°”ì´ ì£¼í–‰ ì´ë¯¸ì§€ì˜ ì‹œë©˜í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ› ï¸ ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤\n",
    "- **ëª¨ë¸**: SegFormer-B2 (Transformer ê¸°ë°˜)\n",
    "- **ë°±ë³¸**: MiT-B2\n",
    "- **ì‚¬ì „ í•™ìŠµ**: Cityscapes (ë„ë¡œ í™˜ê²½ íŠ¹í™”)\n",
    "- **ìµœì í™”**: AdamW + FP16 Mixed Precision\n",
    "- **ì†ì‹¤ í•¨ìˆ˜**: Weighted CrossEntropy (ì¤‘ìš” ê°ì²´ ê°€ì¤‘ì¹˜ ë¶€ì—¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    # SegFormerì˜ permute ì—°ì‚°ê³¼ MPS ë°±ì—”ë“œ ê°„ì— ì¶©ëŒ\n",
    "    # elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    #     return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "# âš™ï¸ ì„¤ì • (Configuration)\n",
    "DATA_DIR = os.path.expanduser(\"~/Projects/LossZero/data/Motorcycle Night Ride Dataset\") \n",
    "JSON_PATH = os.path.join(DATA_DIR, \"COCO_motorcycle (pixel).json\")\n",
    "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "\n",
    "CFG = {\n",
    "    \"project\": \"LossZero\",\n",
    "    \"model_name\": \"nvidia/segformer-b2-finetuned-cityscapes-1024-1024\",\n",
    "    \"img_size\": (352, 352),\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-4,\n",
    "    \"epochs\": 25,\n",
    "    \"device\": get_device()\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CFG['device']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.79s)\n",
      "creating index...\n",
      "index created!\n",
      "Category Mapping: {1329681: 0, 1323885: 1, 1323884: 2, 1323882: 3, 1323881: 4, 1323880: 5}\n"
     ]
    }
   ],
   "source": [
    "def create_mask_from_json(coco, img_id, img_info, id_to_idx):\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
    "    \n",
    "    for ann in anns:\n",
    "        cat_id = ann['category_id']\n",
    "        if cat_id in id_to_idx:\n",
    "            cls_idx = id_to_idx[cat_id]\n",
    "            pixel_mask = coco.annToMask(ann)\n",
    "            mask[pixel_mask == 1] = cls_idx\n",
    "        \n",
    "    return mask\n",
    "\n",
    "def process_single_data(coco, img_id, img_dir, id_to_idx, transform=None):\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_path = os.path.join(img_dir, img_info['file_name'])\n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mask = create_mask_from_json(coco, img_id, img_info, id_to_idx)\n",
    "    \n",
    "    if transform:\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        image, mask = augmented['image'], augmented['mask']\n",
    "    \n",
    "    return image, torch.as_tensor(mask).long()\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG['img_size'][0], CFG['img_size'][1]),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "coco = COCO(JSON_PATH)\n",
    "img_ids = list(coco.imgs.keys())\n",
    "cat_ids = coco.getCatIds()\n",
    "id_to_idx = {cat_id: i for i, cat_id in enumerate(cat_ids)}\n",
    "print(f\"Category Mapping: {id_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238a6ad499d546d4bc7507dd79c00414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mSegformerForSemanticSegmentation LOAD REPORT\u001b[0m from: nvidia/segformer-b2-finetuned-cityscapes-1024-1024\n",
      "Key                           | Status   |                                                                                                    \n",
      "------------------------------+----------+----------------------------------------------------------------------------------------------------\n",
      "decode_head.classifier.bias   | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19]) vs model:torch.Size([6])                      \n",
      "decode_head.classifier.weight | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19, 768, 1, 1]) vs model:torch.Size([6, 768, 1, 1])\n",
      "\n",
      "\u001b[3mNotes:\n",
      "- MISMATCH\u001b[3m\t:ckpt weights were loaded, but they did not match the original empty weight shapes.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "id2label = {i: coco.loadCats(cat_id)[0]['name'] for cat_id, i in id_to_idx.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    CFG['model_name'],\n",
    "    num_labels=len(id_to_idx),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(CFG['device'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=0.01)\n",
    "\n",
    "# âš–ï¸ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (Class Weights)\n",
    "# 0: Rider(2.0), 1: My bike(2.0), 2: Moveable(4.0), 3: Lane Mark(8.0), 4: Road(1.0), 5: Undrivable(1.0)\n",
    "# ë©´ì ì´ ì¢ê³  ì•ˆì „ì— í•µì‹¬ì ì¸ 'ì°¨ì„ (Lane Mark, 8x)'ê³¼ 'ì¥ì• ë¬¼(Moveable, 4x)'ì— ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬\n",
    "weights = torch.tensor([2.0, 2.0, 4.0, 8.0, 1.0, 1.0], dtype=torch.float).to(CFG['device'])\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "scaler = GradScaler('cuda') if CFG['device'] == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ SegFormer-B2 Training Start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5a74be761746d5bba4f4246e7b0111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25] Avg Loss: 1.1270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54ef99c6abb4c4d8a165d6de3c15037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25] Avg Loss: 0.5323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7b0fd2d6cd40e2b54b551e32513db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25] Avg Loss: 0.3795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80594a7a437242989cf93bee2744f26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"ğŸš€ SegFormer-B2 Training Start...\")\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    model.train()\n",
    "    np.random.shuffle(img_ids)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    pbar = tqdm(range(0, len(img_ids), CFG['batch_size']), desc=f\"Epoch {epoch+1}\")\n",
    "    for i in pbar:\n",
    "        batch_ids = img_ids[i : i + CFG['batch_size']]\n",
    "        \n",
    "        images, masks = [], []\n",
    "        for img_id in batch_ids:\n",
    "            img, msk = process_single_data(coco, img_id, IMG_DIR, id_to_idx, train_transform)\n",
    "            images.append(img)\n",
    "            masks.append(msk)\n",
    "            \n",
    "        # Force contiguous input\n",
    "        X = torch.stack(images).to(CFG['device']).contiguous()\n",
    "        y = torch.stack(masks).to(CFG['device']).contiguous()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler:\n",
    "            with autocast('cuda'):\n",
    "                # Force contiguous output\n",
    "                outputs = model(X).logits.contiguous()\n",
    "                upsampled_logits = nn.functional.interpolate(\n",
    "                    outputs, \n",
    "                    size=y.shape[-2:], \n",
    "                    mode=\"bilinear\", \n",
    "                    align_corners=False\n",
    "                ).contiguous()\n",
    "                loss = criterion(upsampled_logits, y)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # Force contiguous output\n",
    "            outputs = model(X).logits.contiguous()\n",
    "            upsampled_logits = nn.functional.interpolate(\n",
    "                outputs, \n",
    "                size=y.shape[-2:], \n",
    "                mode=\"bilinear\", \n",
    "                align_corners=False\n",
    "            ).contiguous()\n",
    "            loss = criterion(upsampled_logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "        \n",
    "    avg_loss = epoch_loss / (len(img_ids) // CFG['batch_size'])\n",
    "    print(f\"Epoch [{epoch+1}/{CFG['epochs']}] Avg Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
