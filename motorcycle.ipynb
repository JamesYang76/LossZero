{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# ğŸï¸ LossZero: Motorcycle Night Ride SegFormer-B2 Optimized\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ **SegFormer-B2** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•¼ê°„ ì˜¤í† ë°”ì´ ì£¼í–‰ ì´ë¯¸ì§€ì˜ ì‹œë©˜í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
                "\n",
                "### ğŸ› ï¸ ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤\n",
                "- **ëª¨ë¸**: SegFormer-B2 (Transformer ê¸°ë°˜)\n",
                "- **ë°±ë³¸**: MiT-B2\n",
                "- **ì‚¬ì „ í•™ìŠµ**: Cityscapes (ë„ë¡œ í™˜ê²½ íŠ¹í™”)\n",
                "- **ìµœì í™”**: AdamW + FP16 Mixed Precision\n",
                "- **ì†ì‹¤ í•¨ìˆ˜**: Weighted CrossEntropy (ì¤‘ìš” ê°ì²´ ê°€ì¤‘ì¹˜ ë¶€ì—¬)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "id": "setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch version: 2.6.0\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import cv2\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from pycocotools.coco import COCO\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
                "from torch.amp import autocast, GradScaler\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "config",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cpu\n"
                    ]
                }
            ],
            "source": [
                "def get_device():\n",
                "    if torch.cuda.is_available():\n",
                "        return \"cuda\"\n",
                "    # SegFormerì˜ permute ì—°ì‚°ê³¼ MPS ë°±ì—”ë“œ ê°„ì— ì¶©ëŒ\n",
                "    # elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
                "    #     return \"mps\"\n",
                "    return \"cpu\"\n",
                "\n",
                "# âš™ï¸ ì„¤ì • (Configuration)\n",
                "DATA_DIR = os.path.expanduser(\"~/Projects/LossZero/data/Motorcycle Night Ride Dataset\") \n",
                "JSON_PATH = os.path.join(DATA_DIR, \"COCO_motorcycle (pixel).json\")\n",
                "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
                "\n",
                "CFG = {\n",
                "    \"project\": \"LossZero\",\n",
                "    \"model_name\": \"nvidia/segformer-b2-finetuned-cityscapes-1024-1024\",\n",
                "    \"img_size\": (352, 352),\n",
                "    \"batch_size\": 4,\n",
                "    \"lr\": 1e-4,\n",
                "    \"epochs\": 25,\n",
                "    \"device\": get_device()\n",
                "}\n",
                "\n",
                "print(f\"Using device: {CFG['device']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dataset",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/ng/j7c3wxhn0lnclyqt41g9tcq80000gn/T/ipykernel_69644/427359751.py:36: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
                        "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3), # ì•¼ê°„ ë…¸ì´ì¦ˆ ëŒ€ì‘\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loading annotations into memory...\n",
                        "Done (t=0.79s)\n",
                        "creating index...\n",
                        "index created!\n",
                        "Category Mapping: {1329681: 0, 1323885: 1, 1323884: 2, 1323882: 3, 1323881: 4, 1323880: 5}\n"
                    ]
                }
            ],
            "source": [
                "def create_mask_from_json(coco, img_id, img_info, id_to_idx):\n",
                "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
                "    anns = coco.loadAnns(ann_ids)\n",
                "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
                "    \n",
                "    for ann in anns:\n",
                "        cat_id = ann['category_id']\n",
                "        if cat_id in id_to_idx:\n",
                "            cls_idx = id_to_idx[cat_id]\n",
                "            pixel_mask = coco.annToMask(ann)\n",
                "            mask[pixel_mask == 1] = cls_idx\n",
                "        \n",
                "    return mask\n",
                "\n",
                "def process_single_data(coco, img_id, img_dir, id_to_idx, transform=None):\n",
                "    img_info = coco.loadImgs(img_id)[0]\n",
                "    img_path = os.path.join(img_dir, img_info['file_name'])\n",
                "    \n",
                "    image = cv2.imread(img_path)\n",
                "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    mask = create_mask_from_json(coco, img_id, img_info, id_to_idx)\n",
                "    \n",
                "    if transform:\n",
                "        augmented = transform(image=image, mask=mask)\n",
                "        image, mask = augmented['image'], augmented['mask']\n",
                "    \n",
                "    return image, torch.as_tensor(mask).long()\n",
                "\n",
                "train_transform = A.Compose([\n",
                "    A.Resize(CFG['img_size'][0], CFG['img_size'][1]),\n",
                "    \n",
                "    # --- ì•¼ê°„ ì „ìš© Augmentation ì¶”ê°€ ---\n",
                "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
                "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
                "    A.RandomGamma(gamma_limit=(80, 120), p=0.5), # ì–´ë‘ìš´ ì €ì¡°ë„ ê°œì„ \n",
                "    A.GaussNoise(std_range=(0.02, 0.05), p=0.3), # ì•¼ê°„ ë…¸ì´ì¦ˆ ëŒ€ì‘\n",
                "\n",
                "    # --- ê¸°í•˜í•™ì  ë³€í˜• (ë°ì´í„° ìˆ˜ ë³´ì¶©ìš©) ---\n",
                "    A.HorizontalFlip(p=0.5), # ì¢Œìš° ë°˜ì „\n",
                "    # 0.0625ëŠ” ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì˜¤ë«ë™ì•ˆ ê²€ì¦ëœ 'ì‚¬ì‹¤ìƒ í‘œì¤€(De Facto Standard)\n",
                "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5), # ì´ë™/í¬ê¸°/íšŒì „\n",
                "\n",
                "    # ImageNet ë°ì´íƒ€ì…‹ì˜ í‰ê· ê°’ ë‚˜ì˜ì§€ ì•ŠìŒ. SegFormerê°€ ImageNet/Cityscapesë¡œ ë°°ì› ìœ¼ë‹ˆê¹Œ\n",
                "    # ëª¨ë¸ì´ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ë°›ì„ ë•Œ: ì…ë ¥_ì´ë¯¸ì§€ = (ì›ë³¸_ì´ë¯¸ì§€ - í‰ê· ) / í‘œì¤€í¸ì°¨\n",
                "    # ì´ë ‡ê²Œ ê³„ì‚°í•´ì£¼ë©´, ì–´ë–¤ ì‚¬ì§„ì´ ë“¤ì–´ì™€ë„ \"í‰ê· ì´ 0ì´ê³  í‘œì¤€í¸ì°¨ê°€ 1ì¸(Standard Normal Distribution)\" ì•„ì£¼ ì˜ˆìœ ë°ì´í„°ë¡œ ë³€ì‹ \n",
                "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
                "    ToTensorV2()\n",
                "])\n",
                "\n",
                "coco = COCO(JSON_PATH)\n",
                "img_ids = list(coco.imgs.keys())\n",
                "cat_ids = coco.getCatIds()\n",
                "id_to_idx = {cat_id: i for i, cat_id in enumerate(cat_ids)}\n",
                "print(f\"Category Mapping: {id_to_idx}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17ecb67c",
            "metadata": {},
            "source": [
                "### ğŸ“‰ í´ë˜ìŠ¤ë³„ ë¶„í¬ ìš”ì•½ (ë‚´ë¦¼ì°¨ìˆœ)\n",
                "\n",
                "1. **Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)**: **42.9%** (ì••ë„ì  1ìœ„)\n",
                "   - ë°°ê²½(í•˜ëŠ˜, ê±´ë¬¼, í’€ìˆ² ë“±)ì´ ì´ë¯¸ì§€ì˜ ì ˆë°˜ ê°€ê¹Œì´ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
                "2. **Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)**: **27.1%**\n",
                "   - ë„ë¡œ ìì²´ë„ ê½¤ ë§ì€ ì˜ì—­ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
                "3. **My bike (ë‚´ ì˜¤í† ë°”ì´)**: **15.8%**\n",
                "   - ì£¼í–‰ì ì‹œì ì´ë¼ ë‚´ ì˜¤í† ë°”ì´ê°€ í•­ìƒ ë³´ì´ê¸° ë•Œë¬¸ì— ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤.\n",
                "4. **Rider (íƒ‘ìŠ¹ì)**: **8.1%**\n",
                "   - ë‹¤ë¥¸ ì˜¤í† ë°”ì´ ìš´ì „ìë‚˜ ë‚´ ì‹ ì²´ê°€ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
                "5. **Moveable (ì´ë™ ë¬¼ì²´)**: **4.7%**\n",
                "   - ë‹¤ë¥¸ ì°¨ëŸ‰, ë³´í–‰ì ë“± ì•ˆì „ì— ê°€ì¥ ì¤‘ìš”í•œ ì¥ì• ë¬¼ì¸ë° ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\n",
                "6. **Lane Mark (ì°¨ì„ )**: **1.4%**\n",
                "   - ê°€ì¥ ì‹¬ê°í•œ ë¶ˆê· í˜•ì…ë‹ˆë‹¤. ë„ë¡œ ì£¼í–‰ì˜ í•µì‹¬ì¸ ì°¨ì„ ì´ ê³ ì‘ 1% ë‚¨ì§“ì…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "id": "model",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "25d40fcf3c5e4a2fa41e9e0e5d6d8244",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading weights:   0%|          | 0/380 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1mSegformerForSemanticSegmentation LOAD REPORT\u001b[0m from: nvidia/segformer-b2-finetuned-cityscapes-1024-1024\n",
                        "Key                           | Status   |                                                                                                    \n",
                        "------------------------------+----------+----------------------------------------------------------------------------------------------------\n",
                        "decode_head.classifier.bias   | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19]) vs model:torch.Size([6])                      \n",
                        "decode_head.classifier.weight | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19, 768, 1, 1]) vs model:torch.Size([6, 768, 1, 1])\n",
                        "\n",
                        "\u001b[3mNotes:\n",
                        "- MISMATCH\u001b[3m\t:ckpt weights were loaded, but they did not match the original empty weight shapes.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "id2label = {i: coco.loadCats(cat_id)[0]['name'] for cat_id, i in id_to_idx.items()}\n",
                "label2id = {v: k for k, v in id2label.items()}\n",
                "\n",
                "model = SegformerForSemanticSegmentation.from_pretrained(\n",
                "    CFG['model_name'],\n",
                "    num_labels=len(id_to_idx),\n",
                "    id2label=id2label,\n",
                "    label2id=label2id,\n",
                "    ignore_mismatched_sizes=True\n",
                ").to(CFG['device'])\n",
                "\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=0.01)\n",
                "\n",
                "# âš–ï¸ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (Class Weights)\n",
                "weights = torch.tensor([\n",
                "    5.0,   # Rider (8.1%) -> ì ë‹¹íˆ ë†’ì„\n",
                "    2.0,   # My bike (15.8%) -> ë‚®ì¶¤ (ì´ë¯¸ ë§ìŒ)\n",
                "    10.0,  # Moveable (4.7%) -> ê°•ë ¥í•˜ê²Œ ë†’ì„\n",
                "    20.0,  # Lane Mark (1.4%) -> ì•„ì£¼ ê°•ë ¥í•˜ê²Œ!! (í•µì‹¬)\n",
                "    1.0,   # Road (27.1%) -> ê¸°ë³¸\n",
                "    0.5    # Undrivable (42.9%) -> ë‚®ì¶¤ (ë„ˆë¬´ ë§ì•„ì„œ ë°©í•´ë¨)\n",
                "], dtype=torch.float).to(CFG['device'])\n",
                "\n",
                "criterion = nn.CrossEntropyLoss(weight=weights)\n",
                "\n",
                "scaler = GradScaler('cuda') if CFG['device'] == 'cuda' else None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "id": "train",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸš€ SegFormer-B2 Training Start...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f0492b40cd1c4dd58344deb9214ef2a5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch [1/25] Avg Loss: 1.3151\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "48636b0d826947539422e55d47ba6e75",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Epoch 2:   0%|          | 0/50 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     42\u001b[39m     upsampled_logits = nn.functional.interpolate(\n\u001b[32m     43\u001b[39m         outputs, \n\u001b[32m     44\u001b[39m         size=y.shape[-\u001b[32m2\u001b[39m:], \n\u001b[32m     45\u001b[39m         mode=\u001b[33m\"\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     46\u001b[39m         align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     47\u001b[39m     ).contiguous()\n\u001b[32m     48\u001b[39m     loss = criterion(upsampled_logits, y)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     optimizer.step()\n\u001b[32m     52\u001b[39m epoch_loss += loss.item()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/envs/aipel/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/envs/aipel/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/envs/aipel/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "print(\"ğŸš€ SegFormer-B2 Training Start...\")\n",
                "\n",
                "for epoch in range(CFG['epochs']):\n",
                "    model.train()\n",
                "    np.random.shuffle(img_ids)\n",
                "    epoch_loss = 0\n",
                "    \n",
                "    pbar = tqdm(range(0, len(img_ids), CFG['batch_size']), desc=f\"Epoch {epoch+1}\")\n",
                "    for i in pbar:\n",
                "        batch_ids = img_ids[i : i + CFG['batch_size']]\n",
                "        \n",
                "        images, masks = [], []\n",
                "        for img_id in batch_ids:\n",
                "            img, msk = process_single_data(coco, img_id, IMG_DIR, id_to_idx, train_transform)\n",
                "            images.append(img)\n",
                "            masks.append(msk)\n",
                "            \n",
                "        # Force contiguous input\n",
                "        X = torch.stack(images).to(CFG['device']).contiguous()\n",
                "        y = torch.stack(masks).to(CFG['device']).contiguous()\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        if scaler:\n",
                "            with autocast('cuda'):\n",
                "                # Force contiguous output\n",
                "                outputs = model(X).logits.contiguous()\n",
                "                upsampled_logits = nn.functional.interpolate(\n",
                "                    outputs, \n",
                "                    size=y.shape[-2:], \n",
                "                    mode=\"bilinear\", \n",
                "                    align_corners=False\n",
                "                ).contiguous()\n",
                "                loss = criterion(upsampled_logits, y)\n",
                "            \n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "        else:\n",
                "            # Force contiguous output\n",
                "            outputs = model(X).logits.contiguous()\n",
                "            upsampled_logits = nn.functional.interpolate(\n",
                "                outputs, \n",
                "                size=y.shape[-2:], \n",
                "                mode=\"bilinear\", \n",
                "                align_corners=False\n",
                "            ).contiguous()\n",
                "            loss = criterion(upsampled_logits, y)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "        pbar.set_postfix(loss=loss.item())\n",
                "        \n",
                "    avg_loss = epoch_loss / (len(img_ids) // CFG['batch_size'])\n",
                "    print(f\"Epoch [{epoch+1}/{CFG['epochs']}] Avg Loss: {avg_loss:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "aipel",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
