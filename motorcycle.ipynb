{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "# ğŸï¸ LossZero: Motorcycle Night Ride SegFormer-B2 Optimized\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **SegFormer-B2** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•¼ê°„ ì˜¤í† ë°”ì´ ì£¼í–‰ ì´ë¯¸ì§€ì˜ ì‹œë©˜í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ› ï¸ ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤\n",
    "- **ëª¨ë¸**: SegFormer-B2 (Transformer ê¸°ë°˜)\n",
    "- **ë°±ë³¸**: MiT-B2\n",
    "- **ì‚¬ì „ í•™ìŠµ**: Cityscapes (ë„ë¡œ í™˜ê²½ íŠ¹í™”)\n",
    "- **ìµœì í™”**: AdamW + FP16 Mixed Precision\n",
    "- **ì†ì‹¤ í•¨ìˆ˜**: Weighted CrossEntropy (ì¤‘ìš” ê°ì²´ ê°€ì¤‘ì¹˜ ë¶€ì—¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1",
    "outputId": "fce71809-6f30-48a6-cd3b-5de8707520af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "## Colab ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-mount",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "colab-mount",
    "outputId": "75570bbe-051b-430c-d55e-c3648c7dfd14"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5",
    "outputId": "19b89677-5aeb-4c21-9d7c-fe09e26b1190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Local Environment\n",
      "Using device: cpu\n",
      "Data directory: /Users/jamesyang/Projects/LossZero/data/Motorcycle Night Ride Dataset\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "\n",
    "    return \"cpu\"\n",
    "\n",
    "def num_worker():\n",
    "    if torch.cuda.is_available():\n",
    "        return os.cpu_count()\n",
    "\n",
    "    return 0\n",
    "\n",
    "# âš™ï¸ ì„¤ì • (Configuration)\n",
    "# DATA_DIR = \"/content/drive/MyDrive/motor_model\"\n",
    "DATA_DIR = \"/home/jovyan/work/motorcycle/Dataset\"\n",
    "# DATA_DIR = os.path.expanduser(\"~/Projects/LossZero/data/Motorcycle Night Ride Dataset\")\n",
    "print(\"Detected Local Environment\")\n",
    "CFG = {\n",
    "    \"project\": \"LossZero\",\n",
    "    \"model_name\": \"nvidia/segformer-b2-finetuned-cityscapes-1024-1024\",\n",
    "    \"img_size\": (384, 672),\n",
    "    \"batch_size\": 8,\n",
    "    \"lr\": 1e-4,\n",
    "    \"epochs\": 20,\n",
    "    \"device\": get_device(),\n",
    "    \"num_worker\": num_worker()\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CFG['device']}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6",
    "outputId": "6ba8842b-9995-40fc-e53c-d008ca5184e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Category Mapping: {1329681: 0, 1323885: 1, 1323884: 2, 1323882: 3, 1323881: 4, 1323880: 5}\n"
     ]
    }
   ],
   "source": [
    "def create_mask_from_json(coco, img_id, img_info, id_to_idx):\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
    "\n",
    "    for ann in anns:\n",
    "        cat_id = ann['category_id']\n",
    "        if cat_id in id_to_idx:\n",
    "            cls_idx = id_to_idx[cat_id]\n",
    "            pixel_mask = coco.annToMask(ann)\n",
    "            mask[pixel_mask == 1] = cls_idx\n",
    "\n",
    "    return mask\n",
    "\n",
    "def process_single_data(coco, img_id, img_dir, id_to_idx, transform=None):\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_path = os.path.join(img_dir, img_info['file_name'])\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = create_mask_from_json(coco, img_id, img_info, id_to_idx)\n",
    "\n",
    "    if transform:\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        image, mask = augmented['image'], augmented['mask']\n",
    "\n",
    "    return image, torch.as_tensor(mask).long()\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    #  ì›ë³¸ í•´ìƒë„ì—ì„œ 480x480 í¬ê¸°ë¡œ ë¬´ì‘ìœ„ ì¶”ì¶œ (í™”ì§ˆ ì €í•˜ ì—†ìŒ)\n",
    "    A.RandomCrop(height=CFG['img_size'][0], width=CFG['img_size'][1], p=1.0),\n",
    "    A.PadIfNeeded(min_height=CFG['img_size'][0], min_width=CFG['img_size'][1], p=1.0),\n",
    "\n",
    "    # --- ì•¼ê°„ ì „ìš© Augmentation ì¶”ê°€ ---\n",
    "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.5), # ì–´ë‘ìš´ ì €ì¡°ë„ ê°œì„ \n",
    "    A.GaussNoise(std_range=(0.02, 0.05), p=0.3), # ì•¼ê°„ ë…¸ì´ì¦ˆ ëŒ€ì‘\n",
    "\n",
    "    # --- ê¸°í•˜í•™ì  ë³€í˜• (ë°ì´í„° ìˆ˜ ë³´ì¶©ìš©) ---\n",
    "    A.HorizontalFlip(p=0.5), # ì¢Œìš° ë°˜ì „\n",
    "    # 0.0625ëŠ” ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì˜¤ë«ë™ì•ˆ ê²€ì¦ëœ 'ì‚¬ì‹¤ìƒ í‘œì¤€(De Facto Standard)\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=25, p=0.5), # ì´ë™/í¬ê¸°/íšŒì „\n",
    "\n",
    "    # ImageNet ë°ì´íƒ€ì…‹ì˜ í‰ê· ê°’ ë‚˜ì˜ì§€ ì•ŠìŒ. SegFormerê°€ ImageNet/Cityscapesë¡œ ë°°ì› ìœ¼ë‹ˆê¹Œ\n",
    "    # ëª¨ë¸ì´ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ë°›ì„ ë•Œ: ì…ë ¥_ì´ë¯¸ì§€ = (ì›ë³¸_ì´ë¯¸ì§€ - í‰ê· ) / í‘œì¤€í¸ì°¨\n",
    "    # ì´ë ‡ê²Œ ê³„ì‚°í•´ì£¼ë©´, ì–´ë–¤ ì‚¬ì§„ì´ ë“¤ì–´ì™€ë„ \"í‰ê· ì´ 0ì´ê³  í‘œì¤€í¸ì°¨ê°€ 1ì¸(Standard Normal Distribution)\" ì•„ì£¼ ì˜ˆìœ ë°ì´í„°ë¡œ ë³€ì‹ \n",
    "    # ì „ì²´ ì•¼ê°„ ë°ì´í„°ì…‹ì˜ Mean/Stdë¥¼ ì§ì ‘ ê³„ì‚°í•œ ê°’\n",
    "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "coco = COCO(JSON_PATH)\n",
    "img_ids = list(coco.imgs.keys())\n",
    "cat_ids = coco.getCatIds()\n",
    "id_to_idx = {cat_id: i for i, cat_id in enumerate(cat_ids)}\n",
    "print(f\"Category Mapping: {id_to_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "7"
   },
   "source": [
    "## Traing / Val ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8",
    "outputId": "666bd43f-13eb-4a20-fdd7-ea79aa7a69cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.95s)\n",
      "creating index...\n",
      "index created!\n",
      "âœ… Data Ready with Copy-Paste Augmentation!\n",
      "   Train=140 (CP Active), Val=40, Test=20\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "class MotorcycleNightRideDataset(Dataset):\n",
    "    def __init__(self, coco, img_ids, img_dir, id_to_idx, transform=None, use_copy_paste=False):\n",
    "        self.coco = coco\n",
    "        self.img_ids = img_ids\n",
    "        self.img_dir = img_dir\n",
    "        self.id_to_idx = id_to_idx\n",
    "        self.transform = transform\n",
    "        self.use_copy_paste = use_copy_paste  # Copy-Paste í™œì„±í™” ì—¬ë¶€ (Trainë§Œ True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def load_image_mask(self, idx):\n",
    "        \"\"\"ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ë¡œë“œí•˜ê³  BGR->RGB ë³€í™˜\"\"\"\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # ë§ˆìŠ¤í¬ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ í™œìš©)\n",
    "        mask = create_mask_from_json(self.coco, img_id, img_info, self.id_to_idx)\n",
    "        return image, mask\n",
    "\n",
    "    def apply_copy_paste(self, image, mask):\n",
    "        \"\"\"\n",
    "        Copy-Paste Augmentation:\n",
    "        ë‹¤ë¥¸ ì´ë¯¸ì§€(Donor)ì—ì„œ 'Lane Mark(3)'ë‚˜ 'Moveable(2)' ê°™ì€ ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ ì˜¤ë ¤ë‚´ì–´\n",
    "        í˜„ì¬ ì´ë¯¸ì§€(Target)ì— ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "        # 1. ê¸°ì¦ì(Donor) ë¬´ì‘ìœ„ ì„ íƒ\n",
    "        donor_idx = random.randint(0, len(self.img_ids) - 1)\n",
    "        donor_img, donor_mask = self.load_image_mask(donor_idx)\n",
    "\n",
    "        # 2. ì˜¤ë ¤ë‚¼ íƒ€ê²Ÿ í´ë˜ìŠ¤ ì •ì˜ (ì°¨ì„ ê³¼ ì›€ì§ì´ëŠ” ë¬¼ì²´ ì§‘ì¤‘ ê³µëµ)\n",
    "        # Lane Mark: 3, Moveable: 2\n",
    "        target_indices = [2, 3]\n",
    "\n",
    "        # donor_maskì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì¸ í”½ì…€ë§Œ True (ë‚˜ë¨¸ì§€ False)\n",
    "        # np.isinì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬\n",
    "        paste_mask = np.isin(donor_mask, target_indices)\n",
    "\n",
    "        # 3. ë¶™ì—¬ë„£ê¸° (Paste)\n",
    "        # í•´ë‹¹ ì˜ì—­ì— ë‚´ìš©ë¬¼ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì‹¤í–‰\n",
    "        if np.any(paste_mask):\n",
    "            # ì´ë¯¸ì§€ ë®ì–´ì“°ê¸°\n",
    "            image[paste_mask] = donor_img[paste_mask]\n",
    "            # ë§ˆìŠ¤í¬ ë®ì–´ì“°ê¸° (ì •ë‹µì§€ ìˆ˜ì •)\n",
    "            mask[paste_mask] = donor_mask[paste_mask]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ\n",
    "        image, mask = self.load_image_mask(idx)\n",
    "\n",
    "        # 2. Copy-Paste ì ìš© (í›ˆë ¨ ë°ì´í„°ì…‹ì´ê³ , 50% í™•ë¥  ë‹¹ì²¨ ì‹œ)\n",
    "        if self.use_copy_paste and random.random() < 0.5:\n",
    "            image, mask = self.apply_copy_paste(image, mask)\n",
    "\n",
    "        # 3. Albumentations ë³€í™˜ (Resize, ColorJitter, Normalization ë“±)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, torch.as_tensor(mask).long()\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° ID ë¶„í•  (7:2:1)\n",
    "coco = COCO(JSON_PATH)\n",
    "all_ids = list(coco.imgs.keys())\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "train_ids, temp_ids = train_test_split(all_ids, test_size=0.3, random_state=42)\n",
    "# Second split: temp_ids into 2/3 for val (0.2 of total), 1/3 for test (0.1 of total)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=1/3, random_state=42)\n",
    "\n",
    "# 2. Transform ì •ì˜ (ê¸°ì¡´ ì •ì˜ í™œìš©)\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG['img_size'][0], CFG['img_size'][1]),\n",
    "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "# Test transform is the same as validation transform\n",
    "test_transform = val_transform\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (â˜…Trainì—ë§Œ Copy-Paste í™œì„±í™”â˜…)\n",
    "train_dataset = MotorcycleNightRideDataset(\n",
    "    coco, train_ids, IMG_DIR, id_to_idx,\n",
    "    transform=train_transform,\n",
    "    use_copy_paste=True  # Copy-Paste ON!\n",
    ")\n",
    "val_dataset = MotorcycleNightRideDataset(\n",
    "    coco, val_ids, IMG_DIR, id_to_idx,\n",
    "    transform=val_transform,\n",
    "    use_copy_paste=False # Valì—ëŠ” ì ˆëŒ€ ì“°ë©´ ì•ˆ ë¨ (ìˆœìˆ˜ í‰ê°€)\n",
    ")\n",
    "test_dataset = MotorcycleNightRideDataset( # New test dataset\n",
    "    coco, test_ids, IMG_DIR, id_to_idx,\n",
    "    transform=test_transform,\n",
    "    use_copy_paste=False # Testì—ëŠ” ì ˆëŒ€ ì“°ë©´ ì•ˆ ë¨ (ìˆœìˆ˜ í‰ê°€)\n",
    ")\n",
    "\n",
    "# 4. ë°ì´í„° ë¡œë” ìƒì„±\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CFG['num_worker'],\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CFG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CFG['num_worker'],\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader( # New test loader\n",
    "    test_dataset,\n",
    "    batch_size=CFG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CFG['num_worker'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Define CFG_EVAL for later use\n",
    "CFG_EVAL = {\n",
    "    \"num_classes\": len(id_to_idx)\n",
    "}\n",
    "\n",
    "print(f\"âœ… Data Ready with Copy-Paste Augmentation!\")\n",
    "print(f\"   Train={len(train_ids)} (CP Active), Val={len(val_ids)}, Test={len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "9"
   },
   "source": [
    "### ğŸ“‰ í´ë˜ìŠ¤ë³„ ë¶„í¬ ìš”ì•½ (ë‚´ë¦¼ì°¨ìˆœ)\n",
    "\n",
    "1. **Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)**: **42.9%** (ì••ë„ì  1ìœ„)\n",
    "   - ë°°ê²½(í•˜ëŠ˜, ê±´ë¬¼, í’€ìˆ² ë“±)ì´ ì´ë¯¸ì§€ì˜ ì ˆë°˜ ê°€ê¹Œì´ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "2. **Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)**: **27.1%**\n",
    "   - ë„ë¡œ ìì²´ë„ ê½¤ ë§ì€ ì˜ì—­ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "3. **My bike (ë‚´ ì˜¤í† ë°”ì´)**: **15.8%**\n",
    "   - ì£¼í–‰ì ì‹œì ì´ë¼ ë‚´ ì˜¤í† ë°”ì´ê°€ í•­ìƒ ë³´ì´ê¸° ë•Œë¬¸ì— ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤.\n",
    "4. **Rider (íƒ‘ìŠ¹ì)**: **8.1%**\n",
    "   - ë‹¤ë¥¸ ì˜¤í† ë°”ì´ ìš´ì „ìë‚˜ ë‚´ ì‹ ì²´ê°€ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
    "5. **Moveable (ì´ë™ ë¬¼ì²´)**: **4.7%**\n",
    "   - ë‹¤ë¥¸ ì°¨ëŸ‰, ë³´í–‰ì ë“± ì•ˆì „ì— ê°€ì¥ ì¤‘ìš”í•œ ì¥ì• ë¬¼ì¸ë° ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\n",
    "6. **Lane Mark (ì°¨ì„ )**: **1.4%**\n",
    "   - ê°€ì¥ ì‹¬ê°í•œ ë¶ˆê· í˜•ì…ë‹ˆë‹¤. ë„ë¡œ ì£¼í–‰ì˜ í•µì‹¬ì¸ ì°¨ì„ ì´ ê³ ì‘ 1% ë‚¨ì§“ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471,
     "referenced_widgets": [
      "c769d5b2aa2e409094ca9b8759d59878",
      "2fc4593323a54bd0862fcf085f9274e6",
      "ea1a830623894e6eabbf21b81068fb12",
      "bd4f1f661e6f4493867170d3d10467d3",
      "707a3a3a181b428a9afc41e08821e3a6",
      "1ae5409bf8e143a3bf93cba26842db35",
      "51686477dc9e4e4e9747f3d6deb3b973",
      "dc6e0ac79b4c4b8e8a2414e76e26a01d",
      "7e913f3f41ef499db743e20f49a7806d",
      "ae9e5e3b4398452aba901bf6cc6d785b",
      "66b94080882a4f40b0b45d5bdd92bf9d",
      "0722ecf90228429cb48ff257c31019d0",
      "4bb2e1505f7b48f7844688504bcbf27f",
      "8463b45fff27433195cc69720d82a211",
      "4bd4dec582d747bd8bd36eb802659c35",
      "5d76b397f5204171a87f6199bdb2f2c5",
      "715a11b1946942bd960b232de28e9fb6",
      "ec6ad001af4d4f5d8b0b25da92f993e8",
      "39ef57594bdb4733bda5127d33032fe3",
      "01a7b8b25fd64001bce07ea9fa5c3b22",
      "7eb7a77d94db4ed9bc1779c59fabda55",
      "c940f72e230f48a29a580dd1fcc4b7fd",
      "af1a70aba6f849da907b39bd050bfe21",
      "8373f2b9779c4b5198049d2276972561",
      "def6a1c78a6e459aad4d960d57b85d5a",
      "d31d800bd26a4c26af67b2d5c458c896",
      "450035d2a49d4ffeb459dedd44d47fe5",
      "a89fcf88404d4a6c8f08d731e1435cbc",
      "a31d02bb1cf8476692ac622fd396b9af",
      "cd48a0018be94fe88fe7c131087a7665",
      "4d2b3c4823314818b8f487f10be04ebf",
      "362d6931e3fe4cc3aca150afabd62470",
      "df9edefb936642dbb1de1d02cf1ab77b",
      "c2f74793ca674c16bc4fb569bd3c9540",
      "d743b96cdc154b3f8408f1813feb34be",
      "2fd3990c654c41b3a22892ed31289705",
      "7f86c1e38d99411eb53f2ccf820db1ec",
      "893b98c1c3af407387cd5f9085e3eee0",
      "abf809ed0ec542bbb05c9baaae297054",
      "34452e54c4de4ccdbd559c05548dfac0",
      "15e9394e60c5444694902320034b8912",
      "53ad725ad4524844b798943257460345",
      "514374788cc44dbd804139c7449a18c0",
      "d8a3f9b5583a4c19a68d873361fe0ca8",
      "e53c4f75ccaa4ae6a63fba1da2ed22f7"
     ]
    },
    "id": "10",
    "outputId": "e0bd0c54-4356-4c39-e376-6bb72e291d9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b5acf46251448bab5d22914b3faf09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mSegformerForSemanticSegmentation LOAD REPORT\u001b[0m from: nvidia/segformer-b2-finetuned-cityscapes-1024-1024\n",
      "Key                           | Status   |                                                                                                    \n",
      "------------------------------+----------+----------------------------------------------------------------------------------------------------\n",
      "decode_head.classifier.bias   | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19]) vs model:torch.Size([6])                      \n",
      "decode_head.classifier.weight | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19, 768, 1, 1]) vs model:torch.Size([6, 768, 1, 1])\n",
      "\n",
      "\u001b[3mNotes:\n",
      "- MISMATCH\u001b[3m\t:ckpt weights were loaded, but they did not match the original empty weight shapes.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "id2label = {i: coco.loadCats(cat_id)[0]['name'] for cat_id, i in id_to_idx.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    CFG['model_name'],\n",
    "    num_labels=len(id_to_idx),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(CFG['device'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CFG['lr'], # Learning Rate\n",
    "    weight_decay=0.05 #ê°€ì¤‘ì¹˜ì˜ ê´€ì„± ì œì–´, ì˜µí‹°ë§ˆì´ì €ì—ì„œ 0.01ì´ë¼ëŠ” ê°’ì€ ë§¤ í•™ìŠµ ë‹¨ê³„(Step)ë§ˆë‹¤ í˜„ì¬ ê°€ì¤‘ì¹˜ ê°’ì„ ì–¼ë§ˆë‚˜ ê¹ì„ì§€ë¥¼ ê²°ì •í•˜ëŠ” ë¹„ìœ¨ì…ë‹ˆë‹¤.\n",
    ")\n",
    "\n",
    "# âš–ï¸ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (Class Weights)\n",
    "weights = torch.tensor([\n",
    "    3.0,   # Rider: 5.0 â†’ 3.0 (ì¤‘ìš”í•˜ì§€ë§Œ ê³¼í•˜ì§€ ì•Šê²Œ)\n",
    "    1.5,   # My bike: 2.0 â†’ 1.5 (ë‚´ ì˜¤í† ë°”ì´ëŠ” ë„ˆë¬´ ì˜ ë§íˆë‹ˆ ì¡°ê¸ˆ ë” ë‚®ì¶¤)\n",
    "    6.0,   # Moveable: 10.0 â†’ 6.0 (ì ˆë°˜ìœ¼ë¡œ ì¤„ì—¬ì„œ ë¶€ë‹´ ì™„í™”)\n",
    "    12.0,  # Lane Mark: 20.0 â†’ 12 (ì—¬ì „íˆ ì œì¼ ê°•ë ¥í•˜ì§€ë§Œ, 20ë°°ëŠ” ë„ˆë¬´ ê°€í˜¹í–ˆìŒ)\n",
    "    1.0,   # Road: 1.0 (ê¸°ì¤€ì  ìœ ì§€)\n",
    "    0.8    # Undrivable: 0.5 â†’ 0.8 (ë°°ê²½ì„ ë„ˆë¬´ ë¬´ì‹œí•´ì„œ ë„ë¡œ ê²½ê³„ê°€ ë¬´ë„ˆì§€ëŠ” ê²ƒ ë°©ì§€)\n",
    "], dtype=torch.float).to(CFG['device'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "scaler = GradScaler('cuda') if CFG['device'] == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e9c6c7b1",
   "metadata": {
    "id": "e9c6c7b1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# [1] ê¸°ë³¸ IoU ê³„ì‚° ë¡œì§ (Category-specific)\n",
    "def compute_category_iou(preds, targets, num_classes):\n",
    "    preds_flat = preds.flatten().cpu().numpy()\n",
    "    targets_flat = targets.flatten().cpu().numpy()\n",
    "    valid_mask = (targets_flat >= 0) & (targets_flat < num_classes)\n",
    "    preds_flat = preds_flat[valid_mask]\n",
    "    targets_flat = targets_flat[valid_mask]\n",
    "    cm = confusion_matrix(targets_flat, preds_flat, labels=range(num_classes))\n",
    "    intersection = np.diag(cm)\n",
    "    ground_truth_set = cm.sum(axis=1)\n",
    "    predicted_set = cm.sum(axis=0)\n",
    "    union = ground_truth_set + predicted_set - intersection\n",
    "    iou = intersection / (union + 1e-6)\n",
    "    return iou\n",
    "\n",
    "# [2] Boundary IoU ê³„ì‚° ë¡œì§\n",
    "def get_boundary(mask, dilation_pixels=2):\n",
    "    mask = mask.astype(np.uint8)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    eroded = cv2.erode(mask, kernel, iterations=dilation_pixels)\n",
    "    boundary = mask - eroded\n",
    "    return boundary\n",
    "\n",
    "def compute_boundary_iou(preds, targets, num_classes, dilation_pixels=2):\n",
    "    preds_np = preds.cpu().numpy()\n",
    "    targets_np = targets.cpu().numpy()\n",
    "    b_ious = []\n",
    "    for c in range(num_classes):\n",
    "        class_preds = (preds_np == c)\n",
    "        class_targets = (targets_np == c)\n",
    "        ious_per_batch = []\n",
    "        for i in range(preds_np.shape[0]):\n",
    "            gt_boundary = get_boundary(class_targets[i], dilation_pixels)\n",
    "            pred_boundary = get_boundary(class_preds[i], dilation_pixels)\n",
    "            intersection = ((gt_boundary > 0) & (pred_boundary > 0)).sum()\n",
    "            union = ((gt_boundary > 0) | (pred_boundary > 0)).sum()\n",
    "            if union == 0:\n",
    "                ious_per_batch.append(1.0)\n",
    "            else:\n",
    "                ious_per_batch.append(intersection / union)\n",
    "        if not ious_per_batch:\n",
    "            b_ious.append(0.0)\n",
    "        else:\n",
    "            b_ious.append(np.mean(ious_per_batch))\n",
    "    return np.array(b_ious)\n",
    "\n",
    "# [3] í†µí•© í‰ê°€ í•¨ìˆ˜ (Metrics Calculation)\n",
    "def evaluate_metrics(preds, targets, num_classes):\n",
    "    \"\"\"ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µì„ ë°›ì•„ ëª¨ë“  ì§€í‘œ(Category IoU, Boundary IoU)ë¥¼ í•œ ë²ˆì— ê³„ì‚°\"\"\"\n",
    "    cat_iou = compute_category_iou(preds, targets, num_classes)\n",
    "    bound_iou = compute_boundary_iou(preds, targets, num_classes)\n",
    "    return cat_iou, bound_iou\n",
    "\n",
    "# [4] ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥ í•¨ìˆ˜ (Report Generation)\n",
    "def print_evaluation_report(avg_cat_iou, avg_bound_iou, id2label=None):\n",
    "    \"\"\"ê³„ì‚°ëœ í‰ê·  IoU ê°’ë“¤ì„ ë°›ì•„ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\"\"\"\n",
    "    print(\"\\n[Validation Report]\")\n",
    "    print(\"  Category-specific IoU:\")\n",
    "    for i, iou in enumerate(avg_cat_iou):\n",
    "        label = id2label[i] if id2label else f\"Class {i}\"\n",
    "        print(f\"    - {label}: {iou:.4f}\")\n",
    "\n",
    "    print(\"\\n  Boundary IoU (Details):\")\n",
    "    for i, iou in enumerate(avg_bound_iou):\n",
    "        label = id2label[i] if id2label else f\"Class {i}\"\n",
    "        print(f\"    - {label}: {iou:.4f}\")\n",
    "\n",
    "    mIoU = np.nanmean(avg_cat_iou)\n",
    "    mBoU = np.nanmean(avg_bound_iou)\n",
    "    print(f\"\\n  --> mIoU: {mIoU:.4f} | mBoU: {mBoU:.4f}\\n\")\n",
    "    return mIoU, mBoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "11",
   "metadata": {
    "id": "11"
   },
   "outputs": [],
   "source": [
    "# [ê³µí†µ ë¡œì§] ë°ì´í„° ì „ì†¡, ì¶”ë¡ , í™•ëŒ€, ì†ì‹¤ ê³„ì‚°\n",
    "def forward_step(model, images, masks, criterion, device):\n",
    "    # ë°ì´í„°ë¥¼ GPU(CUDA) ë˜ëŠ” CPU ì¤‘ ì‹¤ì œ ì—°ì‚°ì´ ì¼ì–´ë‚  ì¥ì¹˜ë¡œ ë³´ë‚¸ë‹¤\n",
    "    # torch.Tensor í˜•íƒœì´ë©° contiguous()ë¡œ ë©”ëª¨ë¦¬ë¥¼ ì •ë ¬í•œë‹¤\n",
    "    X = images.to(device).contiguous()\n",
    "    y = masks.to(device).contiguous()\n",
    "\n",
    "    # Forward Pass\n",
    "    # logits: ìš°ë¦¬ê°€ ì°¾ëŠ” í´ë˜ìŠ¤ë³„ ì ìˆ˜íŒ (í•„ìˆ˜!) -10.5ë‚˜ 15.2 ê°™ì€ ììœ ë¡œìš´ ìˆ«ì\n",
    "    outputs = model(X).logits\n",
    "\n",
    "    # í™•ëŒ€ (Interpolation)\n",
    "    # ëª¨ë¸ ê²°ê³¼ë¬¼(outputs)ì€ ì—°ì‚° íš¨ìœ¨ì„ ìœ„í•´ 96x96ìœ¼ë¡œ ì¶•ì†Œë˜ì–´ ìˆìŒ\n",
    "    # ì´ë¥¼ ì •ë‹µì§€ yì™€ ë˜‘ê°™ì€ í¬ê¸°(384x384)ë¡œ ë¶€ë“œëŸ½ê²Œ í™•ëŒ€(Interpolate)\n",
    "    # y.shape[-2:] -> (384, 384)\n",
    "    upsampled_logits = nn.functional.interpolate(\n",
    "        outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "    )\n",
    "\n",
    "    # ì˜¤ì°¨(Loss) ê³„ì‚°\n",
    "    loss = criterion(upsampled_logits, y)\n",
    "\n",
    "    return loss, upsampled_logits, y\n",
    "\n",
    "# [í•™ìŠµ ë‹¨ê³„] í•œ ì—í­ ë™ì•ˆì˜ í•™ìŠµ ì§‘í–‰\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, scaler=None, epoch=0):\n",
    "    model.train()\n",
    "    train_loss_sum = 0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "\n",
    "    for images, masks in pbar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed Precision ì§€ì› (CUDA ì „ìš©)\n",
    "        if device == 'cuda' and scaler:\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                loss, _, _ = forward_step(model, images, masks, criterion, device)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "            loss, _, _ = forward_step(model, images, masks, criterion, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’ê³¼ ì •ë‹µ ì‚¬ì´ì˜ ê±°ë¦¬ ê¸°ë¡\n",
    "        train_loss_sum += loss.item()\n",
    "        pbar.set_postfix(Loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    return train_loss_sum / len(loader)\n",
    "\n",
    "# [ê²€ì¦ ë‹¨ê³„] ëª¨ë“ˆí™”ëœ í‰ê°€ ë¡œì§ ì ìš©\n",
    "def validate(model, loader, criterion, device, num_classes=6, id2label=None):\n",
    "    model.eval()\n",
    "    val_loss_sum = 0\n",
    "\n",
    "    # ì§€í‘œ ëˆ„ì ìš© ë°°ì—´ (Total Accumulators)\n",
    "    total_cat_ious = np.zeros(num_classes)\n",
    "    total_bound_ious = np.zeros(num_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            # 1. ê³µí†µ ë¡œì§ ì‹¤í–‰ (Loss ê³„ì‚°)\n",
    "            loss, logits, y = forward_step(model, images, masks, criterion, device)\n",
    "            val_loss_sum += loss.item()\n",
    "\n",
    "            # 2. ì˜ˆì¸¡ê°’ ë³€í™˜\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            # 3. í†µí•© í‰ê°€ ëª¨ë“ˆ í˜¸ì¶œ\n",
    "            cat_iou, bound_iou = evaluate_metrics(preds, y, num_classes)\n",
    "            total_cat_ious += cat_iou\n",
    "            total_bound_ious += bound_iou\n",
    "\n",
    "    # ì—í­ í‰ê·  ê³„ì‚°\n",
    "    avg_loss = val_loss_sum / len(loader)\n",
    "    avg_cat_iou = total_cat_ious / len(loader)\n",
    "    avg_bound_iou = total_bound_ious / len(loader)\n",
    "\n",
    "    # 4. ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥ ëª¨ë“ˆ í˜¸ì¶œ\n",
    "    mIoU, mBoU = print_evaluation_report(avg_cat_iou, avg_bound_iou, id2label)\n",
    "\n",
    "    return avg_loss, mIoU, mBoU, avg_cat_iou, avg_bound_iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211691b1",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "39b4718eda7448b58203104c0ae196a2",
      "5a16ccb3a52d41058216f610f92dbc07",
      "6a35056c9649428bb3dd130812fefdc4",
      "b7ededb631dd4245aa89e14eab475dc7",
      "1e860550cac74f73be587522957a2cc9",
      "c57623a7141d4fec8efdb2ebcf599fa6",
      "92cf42a3a2ac4e539ee74aa639c8af9b",
      "d39856996e314c9e93fecad183103b11",
      "bbf64084fdc845fa9612b068c5bd5318",
      "43b0df6fd48c4be2a14bf4a28fb596d1",
      "4f3eb76f7b3b4364947815a84dafa87f",
      "b60b4e59ab6c46b88544180e2a6ab775",
      "f21d79ef06aa4a8b9164fa21aa713499",
      "0c0ec1627ec3423790b19a22c955ad07",
      "ad16e05da4e044dd8bda166a7baf7f32",
      "9500c7ac5d39414c8681b401849240e5",
      "a6ca01da03154d1eaa9cea238c72f10b",
      "1f7023a92f0a4a0cad8e9562dc74d411",
      "69a9d0460ad3467a9a6fa505488e7106"
     ]
    },
    "id": "211691b1",
    "outputId": "2b2fa2fd-d442-49ff-833b-681703db875e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ SegFormer-B2 Training Start with Dual Auto-Save Strategy...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Class_Boundary_IoU/Lane Mark</td><td>â–â–‚â–‚â–ˆ</td></tr><tr><td>Class_Boundary_IoU/Moveable</td><td>â–â–‚â–ˆâ–†</td></tr><tr><td>Class_Boundary_IoU/My bike</td><td>â–ƒâ–â–†â–ˆ</td></tr><tr><td>Class_Boundary_IoU/Rider</td><td>â–â–‚â–ˆâ–ˆ</td></tr><tr><td>Class_Boundary_IoU/Road</td><td>â–„â–â–ˆâ–‡</td></tr><tr><td>Class_Boundary_IoU/Undrivable</td><td>â–â–‚â–…â–ˆ</td></tr><tr><td>Class_IoU/Lane Mark</td><td>â–â–…â–„â–ˆ</td></tr><tr><td>Class_IoU/Moveable</td><td>â–â–ƒâ–‡â–ˆ</td></tr><tr><td>Class_IoU/My bike</td><td>â–â–…â–‡â–ˆ</td></tr><tr><td>Class_IoU/Rider</td><td>â–â–â–ˆâ–‡</td></tr><tr><td>+7</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Class_Boundary_IoU/Lane Mark</td><td>0.02542</td></tr><tr><td>Class_Boundary_IoU/Moveable</td><td>0.01713</td></tr><tr><td>Class_Boundary_IoU/My bike</td><td>0.04687</td></tr><tr><td>Class_Boundary_IoU/Rider</td><td>0.03058</td></tr><tr><td>Class_Boundary_IoU/Road</td><td>0.0471</td></tr><tr><td>Class_Boundary_IoU/Undrivable</td><td>0.03617</td></tr><tr><td>Class_IoU/Lane Mark</td><td>0.12966</td></tr><tr><td>Class_IoU/Moveable</td><td>0.27119</td></tr><tr><td>Class_IoU/My bike</td><td>0.64714</td></tr><tr><td>Class_IoU/Rider</td><td>0.35221</td></tr><tr><td>+7</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-firebrand-4</strong> at: <a href='https://wandb.ai/jamesyang40k-jy-company/LossZero/runs/3nmlrt1b' target=\"_blank\">https://wandb.ai/jamesyang40k-jy-company/LossZero/runs/3nmlrt1b</a><br> View project at: <a href='https://wandb.ai/jamesyang40k-jy-company/LossZero' target=\"_blank\">https://wandb.ai/jamesyang40k-jy-company/LossZero</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260212_120447-3nmlrt1b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jamesyang/Projects/LossZero/wandb/run-20260212_123257-hw8zjrxx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jamesyang40k-jy-company/LossZero/runs/hw8zjrxx' target=\"_blank\">restful-thunder-5</a></strong> to <a href='https://wandb.ai/jamesyang40k-jy-company/LossZero' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jamesyang40k-jy-company/LossZero' target=\"_blank\">https://wandb.ai/jamesyang40k-jy-company/LossZero</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jamesyang40k-jy-company/LossZero/runs/hw8zjrxx' target=\"_blank\">https://wandb.ai/jamesyang40k-jy-company/LossZero/runs/hw8zjrxx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ce660a0773449a8e6a6cf615fc1bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Validation Report]\n",
      "  Category-specific IoU:\n",
      "    - Rider: 0.1162\n",
      "    - My bike: 0.4940\n",
      "    - Moveable: 0.0763\n",
      "    - Lane Mark: 0.0682\n",
      "    - Road: 0.3403\n",
      "    - Undrivable: 0.2445\n",
      "\n",
      "  Boundary IoU (Details):\n",
      "    - Rider: 0.0052\n",
      "    - My bike: 0.0235\n",
      "    - Moveable: 0.0012\n",
      "    - Lane Mark: 0.0316\n",
      "    - Road: 0.0140\n",
      "    - Undrivable: 0.0008\n",
      "\n",
      "  --> mIoU: 0.2233 | mBoU: 0.0127\n",
      "\n",
      "ğŸ“ Epoch [1/20]\n",
      "   Train Loss: 1.5866 | Val Loss: 1.4903\n",
      "   âœ¨ Val mIoU: 0.2233 | mBoU: 0.0127\n",
      "   ğŸ† New Best mIoU! (0.0000 -> 0.2233) Saving...\n",
      "   ğŸ¨ New Best mBoU! (0.0000 -> 0.0127) Saving...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b55d3911fee420f8522be7a8e9fbb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Train]:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Validation Report]\n",
      "  Category-specific IoU:\n",
      "    - Rider: 0.1832\n",
      "    - My bike: 0.5457\n",
      "    - Moveable: 0.1428\n",
      "    - Lane Mark: 0.1242\n",
      "    - Road: 0.4332\n",
      "    - Undrivable: 0.5524\n",
      "\n",
      "  Boundary IoU (Details):\n",
      "    - Rider: 0.0107\n",
      "    - My bike: 0.0128\n",
      "    - Moveable: 0.0052\n",
      "    - Lane Mark: 0.0346\n",
      "    - Road: 0.0233\n",
      "    - Undrivable: 0.0072\n",
      "\n",
      "  --> mIoU: 0.3302 | mBoU: 0.0156\n",
      "\n",
      "ğŸ“ Epoch [2/20]\n",
      "   Train Loss: 1.2212 | Val Loss: 1.2346\n",
      "   âœ¨ Val mIoU: 0.3302 | mBoU: 0.0156\n",
      "   ğŸ† New Best mIoU! (0.2233 -> 0.3302) Saving...\n",
      "   ğŸ¨ New Best mBoU! (0.0127 -> 0.0156) Saving...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ffa15b279b408b8868f2293039a0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Train]:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Validation Report]\n",
      "  Category-specific IoU:\n",
      "    - Rider: 0.3846\n",
      "    - My bike: 0.5911\n",
      "    - Moveable: 0.2713\n",
      "    - Lane Mark: 0.1268\n",
      "    - Road: 0.5714\n",
      "    - Undrivable: 0.7991\n",
      "\n",
      "  Boundary IoU (Details):\n",
      "    - Rider: 0.0181\n",
      "    - My bike: 0.0178\n",
      "    - Moveable: 0.0287\n",
      "    - Lane Mark: 0.0266\n",
      "    - Road: 0.0330\n",
      "    - Undrivable: 0.0364\n",
      "\n",
      "  --> mIoU: 0.4574 | mBoU: 0.0268\n",
      "\n",
      "ğŸ“ Epoch [3/20]\n",
      "   Train Loss: 1.0066 | Val Loss: 1.0433\n",
      "   âœ¨ Val mIoU: 0.4574 | mBoU: 0.0268\n",
      "   ğŸ† New Best mIoU! (0.3302 -> 0.4574) Saving...\n",
      "   ğŸ¨ New Best mBoU! (0.0156 -> 0.0268) Saving...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aca70869b77414a84c3186e15f2a4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Train]:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- ğŸš€ ë©”ì¸ í•™ìŠµ ë£¨í”„ (Auto-Save ê¸°ëŠ¥ íƒ‘ì¬) ---\n",
    "print(\"ğŸš€ SegFormer-B2 Training Start with Dual Auto-Save Strategy...\")\n",
    "\n",
    "wandb.init(project=CFG['project'], config=CFG)\n",
    "\n",
    "best_miou = 0.0\n",
    "best_mbou = 0.0\n",
    "best_miou_epoch = 0\n",
    "\n",
    "save_dir = \"./checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    # 1. í•™ìŠµ ì‹¤í–‰\n",
    "    avg_train_loss = train_one_epoch(model, train_loader, optimizer, criterion, CFG['device'], scaler, epoch)\n",
    "\n",
    "    # 2. ê²€ì¦ ì‹¤í–‰\n",
    "    avg_val_loss, avg_val_miou, avg_val_mbou, mean_cat_ious, mean_bound_ious = validate(model, val_loader, criterion, CFG['device'], num_classes=6, id2label=id2label)\n",
    "\n",
    "\n",
    "    # --- WandB í†µí•© ë¡œê¹… (ì •ë°€ ëª¨ë‹ˆí„°ë§) ---\n",
    "    log_dict = {\n",
    "        'epoch': epoch,\n",
    "        'Loss/Train': avg_train_loss,\n",
    "        'Loss/Val': avg_val_loss,\n",
    "        'Metrics/mIoU': avg_val_miou,\n",
    "        'Metrics/mBoU': avg_val_mbou\n",
    "    }\n",
    "\n",
    "    # í´ë˜ìŠ¤ë³„ ìƒì„¸ IoU ê¸°ë¡\n",
    "    for i, (cat_iou, b_iou) in enumerate(zip(mean_cat_ious, mean_bound_ious)):\n",
    "        cls_name = id2label[i]\n",
    "        log_dict[f'Class_IoU/{cls_name}'] = cat_iou\n",
    "        log_dict[f'Class_Boundary_IoU/{cls_name}'] = b_iou\n",
    "\n",
    "    wandb.log(log_dict)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"ğŸ“ Epoch [{epoch+1}/{CFG['epochs']}]\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"   âœ¨ Val mIoU: {avg_val_miou:.4f} | mBoU: {avg_val_mbou:.4f}\")\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # ğŸ’¾ 3. ì´ì¤‘ ìë™ ì €ì¥ (Dual Auto-Save)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # [ê¸°ì¤€ 1] mIoU ì±”í”¼ì–¸ (ê°€ì¥ ë˜‘ë˜‘í•œ ëª¨ë¸)\n",
    "    if avg_val_miou > best_miou:\n",
    "        print(f\"   ğŸ† New Best mIoU! ({best_miou:.4f} -> {avg_val_miou:.4f}) Saving...\")\n",
    "        best_miou = avg_val_miou\n",
    "        best_miou_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"segformer_best_miou.pth\"))\n",
    "\n",
    "    # [ê¸°ì¤€ 2] mBoU ì±”í”¼ì–¸ (í…Œë‘ë¦¬ ì¥ì¸)\n",
    "    if avg_val_mbou > best_mbou:\n",
    "        print(f\"   ğŸ¨ New Best mBoU! ({best_mbou:.4f} -> {avg_val_mbou:.4f}) Saving...\")\n",
    "        best_mbou = avg_val_mbou\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"segformer_best_mbou.pth\"))\n",
    "\n",
    "    # 0.5 ìˆ˜ì¤€: \"ê¸°ë°˜ì€ ë‹¦ì•˜ìœ¼ë‚˜, ê³ ë“ì  ë¬¸ì œëŠ” í¬ê¸°í•œ ìƒíƒœ\"\n",
    "    # 0.1 ìˆ˜ì¤€: \"ì‹¤ì „ì— íˆ¬ì…í•´ë³¼ ë§Œí•œ ìš°ë“±ìƒ\"\n",
    "    # 0.01 ìˆ˜ì¤€: \"ì™„ë²½, í˜¹ì€ ë„ˆë¬´ ê³¼í•œ ê³µë¶€(ê³¼ì í•©)\"\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\nğŸ‰ Training Complete!\")\n",
    "print(f\"   ğŸ‘‘ Overall Best mIoU: {best_miou:.4f} (at Epoch {best_miou_epoch})\")\n",
    "print(f\"   ğŸ–Œï¸ Overall Best mBoU: {best_mbou:.4f}\")\n",
    "# ë§ˆì§€ë§‰ ìƒíƒœë„ ì €ì¥\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, \"segformer_last.pth\"))\n",
    "\n",
    "wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71022e54",
   "metadata": {
    "id": "71022e54"
   },
   "source": [
    "### ğŸ› ï¸ ì£¼ìš” í‰ê°€ í•­ëª©\n",
    "- **mIoU** (Mean Intersection over Union):\n",
    "  - **Category-specific IoU**\n",
    "  - **Boundary IoU**\n",
    "- **ì‹¤ì‹œê°„ì„± ë° í•˜ë“œì›¨ì–´ ì§€í‘œ**\n",
    "  - **Model Parameters**\n",
    "  - **MACs** Multiply-Accumulate Operations\n",
    "    - y = wx + b ì—ì„œ wx + bë¥¼ 1MAC ì´ë¼ê³  í•œë‹¤.\n",
    "  - **GFLOPs** Giga Floating Point Operations\n",
    "    -  ëª¨ë¸ì„ í•œ ë²ˆ ì‹¤í–‰(Forward Pass)í•  ë•Œ í•„ìš”í•œ ì´ ë¶€ë™ ì†Œìˆ˜ì  ì—°ì‚°ëŸ‰\n",
    "    - ë³´í†µ 1MAC = 2FLOPs\n",
    "  - **Average Inference Latency**\n",
    "  - **Frames Per Second (FPS)**\n",
    "- **Safety-critical Metrics**\n",
    "\n",
    "- TODO\n",
    "  - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ í‰ê°€í•  ê²ƒ ( í˜„ì¬ëŠ” ì „ì²´ ì´ë¯¸ì§€ SET ì‚¬ìš© )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc13abe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bc13abe",
    "outputId": "4543c630-5925-4f2b-dadf-1876131d5c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thop\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.9.0+cu128)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n",
      "thop installed successfully.\n"
     ]
    }
   ],
   "source": [
    "# TODO : requirement.txtë¡œ ë³´ë‚´ì\n",
    "import sys\n",
    "!{sys.executable} -m pip install thop\n",
    "\n",
    "print(\"thop installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934cdc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1934cdc0",
    "outputId": "e3350203-2160-4100-e51c-47b24f7bc183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Model Profiling...\n",
      "Model Parameters (M): 27.35\n",
      "MACs (G): 26.83\n",
      "GFLOPs: 26.83\n",
      "Performing 10 warm-up runs...\n",
      "Measuring latency over 100 inference runs...\n",
      "Average Inference Latency: 83.82 ms\n",
      "Frames Per Second (FPS): 11.93\n",
      "Model Profiling Complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from thop import profile\n",
    "\n",
    "print(\"ğŸš€ Starting Model Profiling...\")\n",
    "\n",
    "# 2. ëª¨ë¸ì„ ìœ„í•œ ë”ë¯¸ ì…ë ¥ í…ì„œ ìƒì„±\n",
    "dummy_input = torch.randn(1, 3, CFG['img_size'][0], CFG['img_size'][1]).to(CFG['device'])\n",
    "\n",
    "# 3. ë”ë¯¸ ì…ë ¥ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ MACs ë° ë§¤ê°œë³€ìˆ˜(params)ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ thop.profile ì‚¬ìš©. verbose=Falseë¡œ ì„¤ì •.\n",
    "macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "\n",
    "# 4. ê³„ì‚°ëœ MACsë¥¼ 1e9ë¡œ ë‚˜ëˆ„ì–´ GFLOPsë¡œ ë³€í™˜.\n",
    "gflops = macs / 1e9\n",
    "\n",
    "print(f\"Model Parameters (M): {params / 1e6:.2f}\")\n",
    "print(f\"MACs (G): {macs / 1e9:.2f}\")\n",
    "print(f\"GFLOPs: {gflops:.2f}\")\n",
    "\n",
    "# 5. ì§€ì—° ì‹œê°„ ë° FPS ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”.\n",
    "num_warmup_runs = 10\n",
    "num_inference_runs = 100\n",
    "total_latency = 0.0\n",
    "\n",
    "# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "model.eval()\n",
    "\n",
    "# 6. ì›Œë°ì—… ì‹¤í–‰ ìˆ˜í–‰\n",
    "print(f\"Performing {num_warmup_runs} warm-up runs...\")\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_warmup_runs):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "# 7. ì¶”ë¡  ì§€ì—° ì‹œê°„ ì¸¡ì •\n",
    "print(f\"Measuring latency over {num_inference_runs} inference runs...\")\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_inference_runs):\n",
    "        start_time = time.perf_counter()\n",
    "        _ = model(dummy_input)\n",
    "        end_time = time.perf_counter()\n",
    "        total_latency += (end_time - start_time)\n",
    "\n",
    "# 8. í‰ê·  ì§€ì—° ì‹œê°„(ms) ê³„ì‚°\n",
    "average_latency_ms = (total_latency / num_inference_runs) * 1000\n",
    "\n",
    "# 9. FPS ê³„ì‚°\n",
    "fps = 1000 / average_latency_ms\n",
    "\n",
    "print(f\"Average Inference Latency: {average_latency_ms:.2f} ms\")\n",
    "print(f\"Frames Per Second (FPS): {fps:.2f}\")\n",
    "print(\"Model Profiling Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cp0ULe5B17zc",
   "metadata": {
    "id": "Cp0ULe5B17zc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "class SafetyEvalMetrics:\n",
    "    def __init__(self, num_classes, class_names):\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names\n",
    "        self.confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "\n",
    "    def update(self, preds, gts):\n",
    "        \"\"\"\n",
    "        í•œ ë°°ì¹˜(Batch) ë˜ëŠ” í•œ í”„ë ˆì„ì˜ ê²°ê³¼ë¥¼ ëˆ„ì í•©ë‹ˆë‹¤.\n",
    "        preds, gts: [Batch, H, W] í˜•íƒœì˜ Tensor ë˜ëŠ” Numpy\n",
    "        \"\"\"\n",
    "        preds = preds.flatten()\n",
    "        gts = gts.flatten()\n",
    "\n",
    "        # ìœ íš¨í•˜ì§€ ì•Šì€ íƒ€ê²Ÿ ê°’ ì œì™¸ (ì˜ˆ: íŒ¨ë”© ë˜ëŠ” ignore_indexê°€ í¬í•¨ëœ ê²½ìš°)\n",
    "        valid_mask = (gts >= 0) & (gts < self.num_classes)\n",
    "        preds = preds[valid_mask]\n",
    "        gts = gts[valid_mask]\n",
    "\n",
    "        # sklearnì˜ confusion_matrixë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ì—…ë°ì´íŠ¸\n",
    "        # labels ì¸ìë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œê³µí•˜ì—¬ ëª¨ë“  í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ë„ë¡ ë³´ì¥\n",
    "        new_cm = confusion_matrix(gts, preds, labels=range(self.num_classes))\n",
    "        self.confusion_matrix += new_cm\n",
    "\n",
    "    def plot_confusion_matrix(self, normalize=True):\n",
    "        \"\"\"\n",
    "        í˜¼ë™ í–‰ë ¬ ì‹œê°í™”\n",
    "        \"\"\"\n",
    "        cm = self.confusion_matrix\n",
    "        if normalize:\n",
    "            # í–‰(Actual) ê¸°ì¤€ ì •ê·œí™”: í•´ë‹¹ í´ë˜ìŠ¤ê°€ ì‹¤ì œ ë¬´ì—‡ìœ¼ë¡œ ì˜ˆì¸¡ë˜ì—ˆëŠ”ì§€ ë¹„ìœ¨ í™•ì¸\n",
    "            # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ 1e-9 ì¶”ê°€\n",
    "            cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\" if normalize else \"d\",\n",
    "                    cmap=\"Blues\", xticklabels=self.class_names, yticklabels=self.class_names)\n",
    "\n",
    "        plt.title('Road Scene Segmentation: Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('Ground Truth Label')\n",
    "        plt.show()\n",
    "\n",
    "    def analyze_safety_risks(self):\n",
    "        \"\"\"\n",
    "        ì¹˜ëª…ì  ì˜¤ë¶„ë¥˜(Safety-Critical) ì§‘ì¤‘ ë¶„ì„\n",
    "        \"\"\"\n",
    "        cm_norm = self.confusion_matrix.astype('float') / (self.confusion_matrix.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
    "\n",
    "        print(\"\\n=== [Safety-Critical Analysis] ===\")\n",
    "\n",
    "        try:\n",
    "            rider_idx = self.class_names.index('Rider')\n",
    "            mybike_idx = self.class_names.index('My bike')\n",
    "            moveable_idx = self.class_names.index('Moveable')\n",
    "            lanemark_idx = self.class_names.index('Lane Mark')\n",
    "            road_idx = self.class_names.index('Road')\n",
    "            undrivable_idx = self.class_names.index('Undrivable')\n",
    "\n",
    "            print(\"--- ê³ ìœ„í—˜ ---\")\n",
    "            # Case 1: Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)ì´ Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)ë¡œ ì˜¤ë¶„ë¥˜ëœ ê²½ìš°\n",
    "            # ì‹¤ì œ ì¥ì• ë¬¼ì´ë‚˜ ìœ„í—˜ ì§€ì—­ì„ ë„ë¡œë¡œ ì¸ì‹í•˜ì—¬ ì¶©ëŒ ìœ„í—˜ì´ ë§¤ìš° ë†’ìŒ.\n",
    "            undrivable_as_road = cm_norm[undrivable_idx, road_idx]\n",
    "            print(f\"1. ì¦‰ê°ì ì¸ ì¶©ëŒ ìœ„í—˜ - 'Undrivable' ì˜ì—­ì˜ {undrivable_as_road:.2%}ê°€ 'Road'ë¡œ ì˜¤ë¶„ë¥˜ ë¨.\")\n",
    "\n",
    "            # Case 2: Moveable (ì´ë™ ë¬¼ì²´)ì´ Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)ë¡œ ì˜¤ë¶„ë¥˜ëœ ê²½ìš°\n",
    "            # ë‹¤ë¥¸ ì°¨ëŸ‰ì´ë‚˜ ë³´í–‰ì ë“± ì¤‘ìš”í•œ ì´ë™ ì¥ì• ë¬¼ì„ ê°ì§€í•˜ì§€ ëª»í•˜ê³  í†µí–‰ ë¶ˆê°€ ì˜ì—­ìœ¼ë¡œ í‘œì‹œí–ˆìŒì„ ì˜ë¯¸.\n",
    "            missed_moveable_as_undrivable = cm_norm[moveable_idx, undrivable_idx]\n",
    "            print(f\"2. ì´ë™ ë¬¼ì²´ ì¶©ëŒ ìœ„í—˜ - 'Moveable' ê°ì²´ì˜ {missed_moveable_as_undrivable:.2%}ê°€ 'Undrivable'ë¡œ ì˜¤ë¶„ë¥˜ ë¨.\")\n",
    "\n",
    "            # Case 3: Moveable (ì´ë™ ë¬¼ì²´)ì´ Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)ë¡œ ì˜¤ë¶„ë¥˜ëœ ê²½ìš°\n",
    "            # ë‹¤ë¥¸ ì°¨ëŸ‰ì´ë‚˜ ë³´í–‰ì ë“± ì¤‘ìš”í•œ ì´ë™ ì¥ì• ë¬¼ì„ ê°ì§€í•˜ì§€ ëª»í•˜ê³  ì•ˆì „í•œ ì£¼í–‰ ê°€ëŠ¥ ì˜ì—­ìœ¼ë¡œ í‘œì‹œí–ˆìŒì„ ì˜ë¯¸.\n",
    "            missed_moveable_as_road = cm_norm[moveable_idx, road_idx]\n",
    "            print(f\"3. ì´ë™ ë¬¼ì²´ ì¶©ëŒ ìœ„í—˜ - 'Moveable' ê°ì²´ì˜ {missed_moveable_as_road:.2%}ê°€ 'Road'ë¡œ ì˜¤ë¶„ë¥˜ ë¨.\")\n",
    "\n",
    "            # Case 4: Rider (íƒ‘ìŠ¹ì)ê°€ Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)ë¡œ ì˜¤ë¶„ë¥˜ëœ ê²½ìš°\n",
    "            # ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œì´ íƒ‘ìŠ¹ì(ìì‹ )ë¥¼ ì¥ì• ë¬¼ë¡œ ì¸ì‹í•˜ì—¬ ë¶ˆí•„ìš”í•œ íšŒí”¼ ê¸°ë™ì´ë‚˜ ì •ì§€ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆìŒ.\n",
    "            rider_as_undrivable = cm_norm[rider_idx, undrivable_idx]\n",
    "            print(f\"4. ì‹œìŠ¤í…œ ì˜¤ì‘ë™ ìœ ë°œ - 'Rider' ê°ì²´ì˜ {rider_as_undrivable:.2%}ê°€ 'Undrivable'ë¡œ ì˜¤ë¶„ë¥˜ ë¨.\")\n",
    "\n",
    "            print(\"\\n--- ì¤‘ìœ„í—˜ ---\")\n",
    "            # Case 5: Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)ê°€ Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)ë¡œ ì˜¤ë¶„ë¥˜ëœ ê²½ìš°\n",
    "            # ì£¼í–‰ ê°€ëŠ¥í•œ ë„ë¡œë¥¼ í†µí–‰ ë¶ˆê°€ëŠ¥í•˜ë‹¤ê³  ê°„ì£¼í•˜ì—¬ ì˜ëª»ëœ ê²½ë¡œ ê³„íšì´ë‚˜ ë¶ˆí•„ìš”í•œ ì œë™ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒ.\n",
    "            road_to_undrivable = cm_norm[road_idx, undrivable_idx]\n",
    "            print(f\"5. ê²½ë¡œ ê³„íš ì˜¤ë¥˜ - 'Road' ì˜ì—­ì˜ {road_to_undrivable:.2%}ê°€ 'Undrivable'ë¡œ ì˜¤ë¶„ë¥˜ ë¨.\")\n",
    "\n",
    "            # Case 6: Lane Mark (ì°¨ì„ )ê°€ Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)ë¡œ ì˜¤ë¶„ë¥˜ëœ ê²½ìš°\n",
    "            # ì°¨ì„ ì´ ë„ë¡œì˜ ì¼ë¶€ë¡œ ì¸ì‹ë˜ì–´ ì°¨ì„  ìœ ì§€ ë³´ì¡° ì‹œìŠ¤í…œì˜ ì˜¤ì‘ë™ì„ ìœ ë°œí•˜ê±°ë‚˜ ì°¨ì„  ì´íƒˆì„ ë°©ì§€í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŒ.\n",
    "            lanemark_as_road = cm_norm[lanemark_idx, road_idx]\n",
    "            print(f\"6. ì°¨ì„  ìœ ì§€ ë³´ì¡° ì˜¤ë¥˜ - 'Lane Mark' ì˜ì—­ì˜ {lanemark_as_road:.2%}ê°€ 'Road'ë¡œ ì˜¤ë¶„ë¥˜ ë¨.\")\n",
    "\n",
    "            print(\"\\n--- ë‚®ì€-ì¤‘ê°„ ìœ„í—˜ ---\")\n",
    "            # Case 7: Rider (íƒ‘ìŠ¹ì)ê°€ My bike (ë‚´ ì˜¤í† ë°”ì´)ë¡œ ì˜¤ë¶„ë¥˜ëœ ê²½ìš°\n",
    "            # ì‹œìŠ¤í…œì˜ ìê¸° ì¸ì‹ì— í˜¼ë€ì„ ì£¼ì§€ë§Œ, ì§ì ‘ì ì¸ ì¶©ëŒ ìœ„í—˜ì€ ë‚®ìŒ. ì •ë°€í•œ ììœ¨ ì£¼í–‰ì—ëŠ” ì˜í–¥.\n",
    "            rider_as_mybike = cm_norm[rider_idx, mybike_idx]\n",
    "            print(f\"7. ìê¸° ì¸ì‹ ì˜¤ë¥˜ - 'Rider' ê°ì²´ì˜ {rider_as_mybike:.2%}ê°€ 'My bike'ë¡œ ì˜¤ë¶„ë¥˜ ë¨.\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"ì˜¤ë¥˜: ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525750d9",
   "metadata": {
    "id": "525750d9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"ğŸš€ Starting Safety Evaluation...\")\n",
    "\n",
    "# Instantiate SafetyEvalMetrics\n",
    "class_names = [name for i, name in sorted(id2label.items())]\n",
    "evaluator = SafetyEvalMetrics(num_classes=CFG_EVAL['num_classes'], class_names=class_names)\n",
    "\n",
    "# Evaluate the model on the validation set to update the confusion matrix\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, masks in val_loader:\n",
    "        X = images.to(CFG['device']).contiguous()\n",
    "        y = masks.to(CFG['device']).contiguous()\n",
    "\n",
    "        outputs = model(X).logits\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            outputs,\n",
    "            size=y.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        preds = upsampled_logits.argmax(dim=1)\n",
    "        evaluator.update(preds.cpu().numpy(), y.cpu().numpy())\n",
    "\n",
    "# Plot the confusion matrix\n",
    "evaluator.plot_confusion_matrix(normalize=True)\n",
    "evaluator.analyze_safety_risks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## ğŸš¦ Grad-CAM: ëª¨ë¸ ì˜ì‚¬ê²°ì • ê·¼ê±° ì‹œê°í™”\n",
    "\n",
    "**1. ë¶„ì„ ëŒ€ìƒ:** `segformer_best_miou.pth` (ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë¡œë“œ)\n",
    "**2. ì„ ì • ì´ìœ :** **mIoU**ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì˜ 'íŒë‹¨ ë…¼ë¦¬'ë¥¼ ì •ì„±ì ìœ¼ë¡œ ê²€ì¦í•˜ê¸° ìœ„í•¨\n",
    "\n",
    "**3. ê¸°ìˆ ì  ìš”ì :**\n",
    "* **Target:** Encoder Stage 4 MLP (ìµœì¢… íŠ¹ì§• ì¶”ì¶œ ë‹¨ê³„)\n",
    "* **Method:** Transformer ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ 2D í”¼ì²˜ë§µ($12 \\times 21$)ìœ¼ë¡œ ë³µì› ì‹œê°í™”\n",
    "* **Layout:** ì›ë³¸ ëŒ€ë¹„ í´ë˜ìŠ¤ë³„ íˆíŠ¸ë§µ 1í–‰ 2ì—´ ë°°ì¹˜ (ë¬´ì‘ìœ„ ìƒ˜í”Œë§)\n",
    "\n",
    "\n",
    "\n",
    "**ğŸ’¡ ìš”ì•½:** \"ê°€ì¥ ë˜‘ë˜‘í•œ ëª¨ë¸(Best mIoU)ì´ ë°¤ê¸¸ ê°ì²´ë¥¼ ì •í™•í•œ ê·¼ê±°ë¡œ ì‹ë³„í•˜ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ ì¦ëª…í•©ë‹ˆë‹¤.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install grad-cam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import SemanticSegmentationTarget\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# [ í•µì‹¬ ] 1. ìµœê³ ì˜ ì„±ëŠ¥ì„ ë‚¸ mIoU ëª¨ë¸(.pth) ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# -------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_path = \"./checkpoints/segformer_best_miou.pth\"\n",
    "\n",
    "# ëª¨ë¸ì— í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì£¼ì… (ì´ ê³¼ì •ì´ ìˆì–´ì•¼ 'ì§€ëŠ¥'ì´ íƒ‘ì¬ë©ë‹ˆë‹¤)\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    print(f\"âœ… í•™ìŠµ ì™„ë£Œëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ ê²½ê³ : {checkpoint_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ë©”ëª¨ë¦¬ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# 2. Grad-CAMìš© Wrapper ë° Reshape í•¨ìˆ˜ ì„¤ì •\n",
    "class SegformerModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(SegformerModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n",
    "\n",
    "def segformer_reshape_transform(tensor, height=12, width=21):\n",
    "    result = tensor.reshape(tensor.size(0), height, width, -1)\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "wrapped_model = SegformerModelWrapper(model).to(device)\n",
    "wrapped_model.eval()\n",
    "\n",
    "# 3. Grad-CAM ê°ì²´ ìƒì„± (Stage 4 MLP íƒ€ê²Ÿ)\n",
    "target_layers = [wrapped_model.model.segformer.encoder.block[3][1].mlp]\n",
    "cam = GradCAM(model=wrapped_model, \n",
    "              target_layers=target_layers, \n",
    "              reshape_transform=segformer_reshape_transform)\n",
    "\n",
    "# 4. ë¬´ì‘ìœ„ ì‚¬ì§„ ì„ íƒ (ë§¤ë²ˆ ì‹¤í–‰ ì‹œë§ˆë‹¤ ìƒˆë¡œìš´ ë°ì´í„°)\n",
    "random_idx = random.randint(0, len(val_dataset) - 1)\n",
    "image, mask = val_dataset[random_idx]\n",
    "input_tensor = image.unsqueeze(0).to(device)\n",
    "input_tensor.requires_grad = True\n",
    "\n",
    "# 5. ë°°ê²½ ì´ë¯¸ì§€ ì¤€ë¹„\n",
    "rgb_img = input_tensor[0].detach().cpu().permute(1, 2, 0).numpy()\n",
    "rgb_img = (rgb_img - rgb_img.min()) / (rgb_img.max() - rgb_img.min())\n",
    "\n",
    "# ==========================================\n",
    "# 6. 4í–‰ 2ì—´(ì´ 8ì¹¸) ê·¸ë¦¬ë“œ ì„¤ì • ë° ì¶œë ¥\n",
    "# ==========================================\n",
    "num_classes = 6\n",
    "fig, axes = plt.subplots(4, 2, figsize=(20, 25))\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(f\"ğŸ“¸ ë¶„ì„ ì‹œì‘: Best mIoU ëª¨ë¸ì„ ì‚¬ìš©í•´ {random_idx}ë²ˆ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# [ì²« ë²ˆì§¸ ì¹¸] ì›ë³¸ ì´ë¯¸ì§€\n",
    "axes[0].imshow(rgb_img)\n",
    "axes[0].set_title(f\"Original Image (Idx: {random_idx})\", fontsize=18, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# [ë‘ ë²ˆì§¸~ì¼ê³± ë²ˆì§¸ ì¹¸] ê° í´ë˜ìŠ¤ë³„ Grad-CAM ê³„ì‚° ë° í•©ì„±\n",
    "output_h, output_w = input_tensor.shape[2] // 4, input_tensor.shape[3] // 4\n",
    "mask_float = np.ones((output_h, output_w), dtype=np.float32)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    class_name = id2label[i]\n",
    "    targets = [SemanticSegmentationTarget(category=i, mask=mask_float)]\n",
    "    \n",
    "    # Grad-CAM ìƒì„±\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    # ê·¸ë¦¬ë“œ ë°°ì¹˜\n",
    "    axes[i+1].imshow(visualization)\n",
    "    axes[i+1].set_title(f\"Class {i}: {class_name.upper()}\", fontsize=18, color='darkred', fontweight='bold')\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "# [ì—¬ëŸ ë²ˆì§¸ ì¹¸] ì •ë³´ í‘œì‹œ\n",
    "axes[7].axis('off')\n",
    "axes[7].text(0.5, 0.5, f\"Analysis Model: Best mIoU\\nData Index: {random_idx}\\nTarget: Multi-Class Logic\", \n",
    "             ha='center', va='center', fontsize=16, color='gray', style='italic', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… ëª¨ë“  ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ì‚¬ìš©í•œ ëª¨ë¸: {checkpoint_path})\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}