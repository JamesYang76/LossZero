{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üèçÔ∏è LossZero: Motorcycle Night Ride SegFormer-B2 Optimized\n",
    "\n",
    "Ïù¥ ÎÖ∏Ìä∏Î∂ÅÏùÄ **SegFormer-B2** Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏïºÍ∞Ñ Ïò§ÌÜ†Î∞îÏù¥ Ï£ºÌñâ Ïù¥ÎØ∏ÏßÄÏùò ÏãúÎ©òÌã± ÏÑ∏Í∑∏Î©òÌÖåÏù¥ÏÖòÏùÑ ÏàòÌñâÌï©ÎãàÎã§.\n",
    "\n",
    "### üõ†Ô∏è Ï£ºÏöî ÏãúÎÇòÎ¶¨Ïò§\n",
    "- **Î™®Îç∏**: SegFormer-B2 (Transformer Í∏∞Î∞ò)\n",
    "- **Î∞±Î≥∏**: MiT-B2\n",
    "- **ÏÇ¨Ï†Ñ ÌïôÏäµ**: Cityscapes (ÎèÑÎ°ú ÌôòÍ≤Ω ÌäπÌôî)\n",
    "- **ÏµúÏ†ÅÌôî**: AdamW + FP16 Mixed Precision\n",
    "- **ÏÜêÏã§ Ìï®Ïàò**: Weighted CrossEntropy (Ï§ëÏöî Í∞ùÏ≤¥ Í∞ÄÏ§ëÏπò Î∂ÄÏó¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup",
    "outputId": "f6613083-91f9-4ae4-ffd9-c389c34b61ae"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "8w7h3L2Ys1pf"
   },
   "source": [
    "## Colab Ïó∞Í≤∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-mount",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "config",
    "outputId": "ba37f54f-5fb9-418d-f013-6c95f4790c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "   # elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "   #     return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "# ‚öôÔ∏è ÏÑ§Ï†ï (Configuration)\n",
    "#DATA_DIR = \"/content/drive/MyDrive/motor_model\"\n",
    "DATA_DIR = os.path.expanduser(\"~/Projects/LossZero/data/Motorcycle Night Ride Dataset\")\n",
    "print(\"Detected Local Environment\")\n",
    "\n",
    "JSON_PATH = os.path.join(DATA_DIR, \"COCO_motorcycle (pixel).json\")\n",
    "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "\n",
    "CFG = {\n",
    "    \"project\": \"LossZero\",\n",
    "    \"model_name\": \"nvidia/segformer-b2-finetuned-cityscapes-1024-1024\",\n",
    "    \"img_size\": (352, 352),\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-4,\n",
    "    \"epochs\": 25,\n",
    "    \"device\": get_device()\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CFG['device']}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dataset",
    "outputId": "a175932e-0de9-4f41-f50f-dcdf808db85c"
   },
   "outputs": [],
   "source": [
    "def create_mask_from_json(coco, img_id, img_info, id_to_idx):\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
    "\n",
    "    for ann in anns:\n",
    "        cat_id = ann['category_id']\n",
    "        if cat_id in id_to_idx:\n",
    "            cls_idx = id_to_idx[cat_id]\n",
    "            pixel_mask = coco.annToMask(ann)\n",
    "            mask[pixel_mask == 1] = cls_idx\n",
    "\n",
    "    return mask\n",
    "\n",
    "def process_single_data(coco, img_id, img_dir, id_to_idx, transform=None):\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_path = os.path.join(img_dir, img_info['file_name'])\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = create_mask_from_json(coco, img_id, img_info, id_to_idx)\n",
    "\n",
    "    if transform:\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        image, mask = augmented['image'], augmented['mask']\n",
    "\n",
    "    return image, torch.as_tensor(mask).long()\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    #  ÏõêÎ≥∏ Ìï¥ÏÉÅÎèÑÏóêÏÑú 352x352 ÌÅ¨Í∏∞Î°ú Î¨¥ÏûëÏúÑ Ï∂îÏ∂ú (ÌôîÏßà Ï†ÄÌïò ÏóÜÏùå)\n",
    "    A.RandomCrop(height=CFG['img_size'][0], width=CFG['img_size'][1], p=1.0),\n",
    "    A.PadIfNeeded(min_height=CFG['img_size'][0], min_width=CFG['img_size'][1], p=1.0),\n",
    "\n",
    "    # --- ÏïºÍ∞Ñ Ï†ÑÏö© Augmentation Ï∂îÍ∞Ä ---\n",
    "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.5), # Ïñ¥ÎëêÏö¥ Ï†ÄÏ°∞ÎèÑ Í∞úÏÑ†\n",
    "    A.GaussNoise(std_range=(0.02, 0.05), p=0.3), # ÏïºÍ∞Ñ ÎÖ∏Ïù¥Ï¶à ÎåÄÏùë\n",
    "\n",
    "    # --- Í∏∞ÌïòÌïôÏ†Å Î≥ÄÌòï (Îç∞Ïù¥ÌÑ∞ Ïàò Î≥¥Ï∂©Ïö©) ---\n",
    "    A.HorizontalFlip(p=0.5), # Ï¢åÏö∞ Î∞òÏ†Ñ\n",
    "    # 0.0625Îäî Î®∏Ïã†Îü¨Îãù/Îî•Îü¨Îãù Ïª§ÎÆ§ÎãàÌã∞ÏóêÏÑú Ïò§Îû´ÎèôÏïà Í≤ÄÏ¶ùÎêú 'ÏÇ¨Ïã§ÏÉÅ ÌëúÏ§Ä(De Facto Standard)\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5), # Ïù¥Îèô/ÌÅ¨Í∏∞/ÌöåÏ†Ñ\n",
    "\n",
    "    # ImageNet Îç∞Ïù¥ÌÉÄÏÖãÏùò ÌèâÍ∑†Í∞í ÎÇòÏÅòÏßÄ ÏïäÏùå. SegFormerÍ∞Ä ImageNet/CityscapesÎ°ú Î∞∞Ïõ†ÏúºÎãàÍπå\n",
    "    # Î™®Îç∏Ïù¥ ÏÉàÎ°úÏö¥ ÏÇ¨ÏßÑÏùÑ Î∞õÏùÑ Îïå: ÏûÖÎ†•_Ïù¥ÎØ∏ÏßÄ = (ÏõêÎ≥∏_Ïù¥ÎØ∏ÏßÄ - ÌèâÍ∑†) / ÌëúÏ§ÄÌé∏Ï∞®\n",
    "    # Ïù¥Î†áÍ≤å Í≥ÑÏÇ∞Ìï¥Ï£ºÎ©¥, Ïñ¥Îñ§ ÏÇ¨ÏßÑÏù¥ Îì§Ïñ¥ÏôÄÎèÑ \"ÌèâÍ∑†Ïù¥ 0Ïù¥Í≥† ÌëúÏ§ÄÌé∏Ï∞®Í∞Ä 1Ïù∏(Standard Normal Distribution)\" ÏïÑÏ£º ÏòàÏÅú Îç∞Ïù¥ÌÑ∞Î°ú Î≥ÄÏã†\n",
    "    # Ï†ÑÏ≤¥ ÏïºÍ∞Ñ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Mean/StdÎ•º ÏßÅÏ†ë Í≥ÑÏÇ∞Ìïú Í∞í\n",
    "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "coco = COCO(JSON_PATH)\n",
    "img_ids = list(coco.imgs.keys())\n",
    "cat_ids = coco.getCatIds()\n",
    "id_to_idx = {cat_id: i for i, cat_id in enumerate(cat_ids)}\n",
    "print(f\"Category Mapping: {id_to_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "PaxYL05itR0D"
   },
   "source": [
    "## Traing / Val Î∂Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSc3mNS_tRHF",
    "outputId": "47fb854a-41eb-4714-9bd3-7ebbf73847ce"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MotorcycleNightRideDataset(Dataset):\n",
    "    def __init__(self, coco, img_ids, img_dir, id_to_idx, transform=None):\n",
    "        self.coco = coco\n",
    "        self.img_ids = img_ids\n",
    "        self.img_dir = img_dir\n",
    "        self.id_to_idx = id_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        image, mask = process_single_data(self.coco, img_id, self.img_dir, self.id_to_idx, self.transform)\n",
    "        return image, mask\n",
    "\n",
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ID Î∂ÑÌï† (8:2)\n",
    "coco = COCO(JSON_PATH)\n",
    "all_ids = list(coco.imgs.keys())\n",
    "train_ids, val_ids = train_test_split(all_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Transform Ï†ïÏùò (Í∏∞Ï°¥ Ï†ïÏùò ÌôúÏö© Î∞è ValÏö© Ï∂îÍ∞Ä)\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG['img_size'][0], CFG['img_size'][1]),\n",
    "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# 3. Îç∞Ïù¥ÌÑ∞ÏÖã Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\n",
    "train_dataset = MotorcycleNightRideDataset(coco, train_ids, IMG_DIR, id_to_idx, train_transform)\n",
    "val_dataset = MotorcycleNightRideDataset(coco, val_ids, IMG_DIR, id_to_idx, val_transform)\n",
    "\n",
    "# 4. Îç∞Ïù¥ÌÑ∞ Î°úÎçî ÏÉùÏÑ±\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CFG['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=os.cpu_count()\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CFG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=os.cpu_count()\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data Ready: Train={len(train_ids)}, Val={len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "17ecb67c"
   },
   "source": [
    "### üìâ ÌÅ¥ÎûòÏä§Î≥Ñ Î∂ÑÌè¨ ÏöîÏïΩ (ÎÇ¥Î¶ºÏ∞®Ïàú)\n",
    "\n",
    "1. **Undrivable (Ï£ºÌñâ Î∂àÍ∞Ä ÏòÅÏó≠)**: **42.9%** (ÏïïÎèÑÏ†Å 1ÏúÑ)\n",
    "   - Î∞∞Í≤Ω(ÌïòÎäò, Í±¥Î¨º, ÌíÄÏà≤ Îì±)Ïù¥ Ïù¥ÎØ∏ÏßÄÏùò Ï†àÎ∞ò Í∞ÄÍπåÏù¥ Ï∞®ÏßÄÌï©ÎãàÎã§.\n",
    "2. **Road (Ï£ºÌñâ Í∞ÄÎä• ÎèÑÎ°ú)**: **27.1%**\n",
    "   - ÎèÑÎ°ú ÏûêÏ≤¥ÎèÑ ÍΩ§ ÎßéÏùÄ ÏòÅÏó≠ÏùÑ Ï∞®ÏßÄÌï©ÎãàÎã§.\n",
    "3. **My bike (ÎÇ¥ Ïò§ÌÜ†Î∞îÏù¥)**: **15.8%**\n",
    "   - Ï£ºÌñâÏûê ÏãúÏ†êÏù¥Îùº ÎÇ¥ Ïò§ÌÜ†Î∞îÏù¥Í∞Ä Ìï≠ÏÉÅ Î≥¥Ïù¥Í∏∞ ÎïåÎ¨∏Ïóê ÎπÑÏú®Ïù¥ ÎÜíÏäµÎãàÎã§.\n",
    "4. **Rider (ÌÉëÏäπÏûê)**: **8.1%**\n",
    "   - Îã§Î•∏ Ïò§ÌÜ†Î∞îÏù¥ Ïö¥Ï†ÑÏûêÎÇò ÎÇ¥ Ïã†Ï≤¥Í∞Ä Ìè¨Ìï®Îêú Í≤ÉÏúºÎ°ú Î≥¥ÏûÖÎãàÎã§.\n",
    "5. **Moveable (Ïù¥Îèô Î¨ºÏ≤¥)**: **4.7%**\n",
    "   - Îã§Î•∏ Ï∞®Îüâ, Î≥¥ÌñâÏûê Îì± ÏïàÏ†ÑÏóê Í∞ÄÏû• Ï§ëÏöîÌïú Ïû•Ïï†Î¨ºÏù∏Îç∞ ÎπÑÏú®Ïù¥ Îß§Ïö∞ ÎÇÆÏäµÎãàÎã§.\n",
    "6. **Lane Mark (Ï∞®ÏÑ†)**: **1.4%**\n",
    "   - Í∞ÄÏû• Ïã¨Í∞ÅÌïú Î∂àÍ∑†ÌòïÏûÖÎãàÎã§. ÎèÑÎ°ú Ï£ºÌñâÏùò ÌïµÏã¨Ïù∏ Ï∞®ÏÑ†Ïù¥ Í≥†Ïûë 1% ÎÇ®ÏßìÏûÖÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471,
     "referenced_widgets": [
      "c769d5b2aa2e409094ca9b8759d59878",
      "2fc4593323a54bd0862fcf085f9274e6",
      "ea1a830623894e6eabbf21b81068fb12",
      "bd4f1f661e6f4493867170d3d10467d3",
      "707a3a3a181b428a9afc41e08821e3a6",
      "1ae5409bf8e143a3bf93cba26842db35",
      "51686477dc9e4e4e9747f3d6deb3b973",
      "dc6e0ac79b4c4b8e8a2414e76e26a01d",
      "7e913f3f41ef499db743e20f49a7806d",
      "ae9e5e3b4398452aba901bf6cc6d785b",
      "66b94080882a4f40b0b45d5bdd92bf9d",
      "0722ecf90228429cb48ff257c31019d0",
      "4bb2e1505f7b48f7844688504bcbf27f",
      "8463b45fff27433195cc69720d82a211",
      "4bd4dec582d747bd8bd36eb802659c35",
      "5d76b397f5204171a87f6199bdb2f2c5",
      "715a11b1946942bd960b232de28e9fb6",
      "ec6ad001af4d4f5d8b0b25da92f993e8",
      "39ef57594bdb4733bda5127d33032fe3",
      "01a7b8b25fd64001bce07ea9fa5c3b22",
      "7eb7a77d94db4ed9bc1779c59fabda55",
      "c940f72e230f48a29a580dd1fcc4b7fd",
      "af1a70aba6f849da907b39bd050bfe21",
      "8373f2b9779c4b5198049d2276972561",
      "def6a1c78a6e459aad4d960d57b85d5a",
      "d31d800bd26a4c26af67b2d5c458c896",
      "450035d2a49d4ffeb459dedd44d47fe5",
      "a89fcf88404d4a6c8f08d731e1435cbc",
      "a31d02bb1cf8476692ac622fd396b9af",
      "cd48a0018be94fe88fe7c131087a7665",
      "4d2b3c4823314818b8f487f10be04ebf",
      "362d6931e3fe4cc3aca150afabd62470",
      "df9edefb936642dbb1de1d02cf1ab77b",
      "c2f74793ca674c16bc4fb569bd3c9540",
      "d743b96cdc154b3f8408f1813feb34be",
      "2fd3990c654c41b3a22892ed31289705",
      "7f86c1e38d99411eb53f2ccf820db1ec",
      "893b98c1c3af407387cd5f9085e3eee0",
      "abf809ed0ec542bbb05c9baaae297054",
      "34452e54c4de4ccdbd559c05548dfac0",
      "15e9394e60c5444694902320034b8912",
      "53ad725ad4524844b798943257460345",
      "514374788cc44dbd804139c7449a18c0",
      "d8a3f9b5583a4c19a68d873361fe0ca8"
     ]
    },
    "id": "model",
    "outputId": "e0bd0c54-4356-4c39-e376-6bb72e291d9e"
   },
   "outputs": [],
   "source": [
    "id2label = {i: coco.loadCats(cat_id)[0]['name'] for cat_id, i in id_to_idx.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    CFG['model_name'],\n",
    "    num_labels=len(id_to_idx),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(CFG['device'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=0.01)\n",
    "\n",
    "# ‚öñÔ∏è ÌÅ¥ÎûòÏä§Î≥Ñ Í∞ÄÏ§ëÏπò ÏÑ§Ï†ï (Class Weights)\n",
    "weights = torch.tensor([\n",
    "    5.0,   # Rider (8.1%) -> Ï†ÅÎãπÌûà ÎÜíÏûÑ\n",
    "    2.0,   # My bike (15.8%) -> ÎÇÆÏ∂§ (Ïù¥ÎØ∏ ÎßéÏùå)\n",
    "    10.0,  # Moveable (4.7%) -> Í∞ïÎ†•ÌïòÍ≤å ÎÜíÏûÑ\n",
    "    20.0,  # Lane Mark (1.4%) -> ÏïÑÏ£º Í∞ïÎ†•ÌïòÍ≤å!! (ÌïµÏã¨)\n",
    "    1.0,   # Road (27.1%) -> Í∏∞Î≥∏\n",
    "    0.5    # Undrivable (42.9%) -> ÎÇÆÏ∂§ (ÎÑàÎ¨¥ ÎßéÏïÑÏÑú Î∞©Ìï¥Îê®)\n",
    "], dtype=torch.float).to(CFG['device'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "scaler = GradScaler('cuda') if CFG['device'] == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517,
     "referenced_widgets": [
      "eacd895341274ca083d8ddc1a3879ba4",
      "e35f377246f341738008871078631420",
      "fcb2f2354f2144d4929fc3857b63f00f",
      "70a7f999804b4a008a6d9790a4f39f3a",
      "7a53a9c0e8fe4f599487170344613431",
      "4162fa761b114e70b3db0e6ac5b477dc",
      "a945ecf5247846cc8e3158bae8601127",
      "2ea75b126d1a414cba6807404a86fc1f",
      "a501ab8a0ab14f76b28c83fbfd1d10aa",
      "a51dbb649b514185a751f7d012138fbf",
      "e9bd4700a6ef4cf9b2ff6ed5671ac8a8"
     ]
    },
    "id": "train",
    "outputId": "4e8fc070-2386-4158-8ab7-ccb951632f2b"
   },
   "outputs": [],
   "source": [
    "print(\"üöÄ SegFormer-B2 Training Start...\")\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss_sum = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for images, masks in pbar:\n",
    "        X = images.to(CFG['device']).contiguous()\n",
    "        y = masks.to(CFG['device']).contiguous()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision ÏßÄÏõê (CUDA Ï†ÑÏö©)\n",
    "        if CFG['device'] == 'cuda' and scaler:\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(X).logits\n",
    "                upsampled_logits = nn.functional.interpolate(outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss = criterion(upsampled_logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(X).logits\n",
    "            upsampled_logits = nn.functional.interpolate(outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = criterion(upsampled_logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss_sum += loss.item()\n",
    "        pbar.set_postfix(Loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    avg_train_loss = train_loss_sum / len(train_loader)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            X = images.to(CFG['device']).contiguous()\n",
    "            y = masks.to(CFG['device']).contiguous()\n",
    "            \n",
    "            outputs = model(X).logits\n",
    "            upsampled_logits = nn.functional.interpolate(outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = criterion(upsampled_logits, y)\n",
    "            val_loss_sum += loss.item()\n",
    "            \n",
    "    avg_val_loss = val_loss_sum / len(val_loader)\n",
    "    print(f\"üìù Epoch [{epoch+1}/{CFG['epochs']}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aipel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
