{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸï¸ LossZero: Motorcycle Night Ride SegFormer-B2 Optimized\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **SegFormer-B2** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•¼ê°„ ì˜¤í† ë°”ì´ ì£¼í–‰ ì´ë¯¸ì§€ì˜ ì‹œë©˜í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ› ï¸ ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤\n",
    "- **ëª¨ë¸**: SegFormer-B2 (Transformer ê¸°ë°˜)\n",
    "- **ë°±ë³¸**: MiT-B2\n",
    "- **ì‚¬ì „ í•™ìŠµ**: Cityscapes (ë„ë¡œ í™˜ê²½ íŠ¹í™”)\n",
    "- **ìµœì í™”**: AdamW + FP16 Mixed Precision\n",
    "- **ì†ì‹¤ í•¨ìˆ˜**: Weighted CrossEntropy (ì¤‘ìš” ê°ì²´ ê°€ì¤‘ì¹˜ ë¶€ì—¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup",
    "outputId": "f6613083-91f9-4ae4-ffd9-c389c34b61ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b19ea58-30bf-4be6-968c-0c478e5d25f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: (1) Create a W&B account\n",
      "wandb: (2) Use an existing W&B account\n",
      "wandb: (3) Don't visualize my results\n",
      "wandb: Enter your choice:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: You chose 'Use an existing W&B account'\n",
      "wandb: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: Create a new API key at: https://wandb.ai/authorize?ref=models\n",
      "wandb: Store your API key securely and do not share it.\n",
      "wandb: Paste your API key and hit enter:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: No netrc file found, creating one.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\GoodDay1\\_netrc\n",
      "wandb: Currently logged in as: vlux22 (vlux22-free) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import wandb \n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "8w7h3L2Ys1pf"
   },
   "source": [
    "## Colab ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-mount",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "config",
    "outputId": "ba37f54f-5fb9-418d-f013-6c95f4790c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Local Environment\n",
      "Using device: cpu\n",
      "Data directory: ./motor_model\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "\n",
    "    return \"cpu\"\n",
    "\n",
    "def num_worker():\n",
    "    if torch.cuda.is_available():\n",
    "        return os.cpu_count()\n",
    "\n",
    "    return 0\n",
    "\n",
    "# âš™ï¸ ì„¤ì • (Configuration)\n",
    "#DATA_DIR = \"/content/drive/MyDrive/motor_model\"\n",
    "DATA_DIR = \"./motor_model\"\n",
    "#DATA_DIR = os.path.expanduser(\"~/Projects/LossZero/data/Motorcycle Night Ride Dataset\")\n",
    "print(\"Detected Local Environment\")\n",
    "\n",
    "JSON_PATH = os.path.join(DATA_DIR, \"COCO_motorcycle (pixel).json\")\n",
    "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "\n",
    "CFG = {\n",
    "    \"project\": \"LossZero\",\n",
    "    \"model_name\": \"nvidia/segformer-b2-finetuned-cityscapes-1024-1024\",\n",
    "    \"img_size\": (352, 352),\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 1e-4,\n",
    "    \"epochs\": 25,\n",
    "    \"device\": get_device(),\n",
    "    \"num_worker\": num_worker()\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CFG['device']}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dataset",
    "outputId": "a175932e-0de9-4f41-f50f-dcdf808db85c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Category Mapping: {1329681: 0, 1323885: 1, 1323884: 2, 1323882: 3, 1323881: 4, 1323880: 5}\n"
     ]
    }
   ],
   "source": [
    "def create_mask_from_json(coco, img_id, img_info, id_to_idx):\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
    "\n",
    "    for ann in anns:\n",
    "        cat_id = ann['category_id']\n",
    "        if cat_id in id_to_idx:\n",
    "            cls_idx = id_to_idx[cat_id]\n",
    "            pixel_mask = coco.annToMask(ann)\n",
    "            mask[pixel_mask == 1] = cls_idx\n",
    "\n",
    "    return mask\n",
    "\n",
    "def process_single_data(coco, img_id, img_dir, id_to_idx, transform=None):\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_path = os.path.join(img_dir, img_info['file_name'])\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = create_mask_from_json(coco, img_id, img_info, id_to_idx)\n",
    "\n",
    "    if transform:\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        image, mask = augmented['image'], augmented['mask']\n",
    "\n",
    "    return image, torch.as_tensor(mask).long()\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    #  ì›ë³¸ í•´ìƒë„ì—ì„œ 352x352 í¬ê¸°ë¡œ ë¬´ì‘ìœ„ ì¶”ì¶œ (í™”ì§ˆ ì €í•˜ ì—†ìŒ)\n",
    "    A.RandomCrop(height=CFG['img_size'][0], width=CFG['img_size'][1], p=1.0),\n",
    "    A.PadIfNeeded(min_height=CFG['img_size'][0], min_width=CFG['img_size'][1], p=1.0),\n",
    "\n",
    "    # --- ì•¼ê°„ ì „ìš© Augmentation ì¶”ê°€ ---\n",
    "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.5), # ì–´ë‘ìš´ ì €ì¡°ë„ ê°œì„ \n",
    "    A.GaussNoise(std_range=(0.02, 0.05), p=0.3), # ì•¼ê°„ ë…¸ì´ì¦ˆ ëŒ€ì‘\n",
    "\n",
    "    # --- ê¸°í•˜í•™ì  ë³€í˜• (ë°ì´í„° ìˆ˜ ë³´ì¶©ìš©) ---\n",
    "    A.HorizontalFlip(p=0.5), # ì¢Œìš° ë°˜ì „\n",
    "    # 0.0625ëŠ” ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì˜¤ë«ë™ì•ˆ ê²€ì¦ëœ 'ì‚¬ì‹¤ìƒ í‘œì¤€(De Facto Standard)\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5), # ì´ë™/í¬ê¸°/íšŒì „\n",
    "\n",
    "    # ImageNet ë°ì´íƒ€ì…‹ì˜ í‰ê· ê°’ ë‚˜ì˜ì§€ ì•ŠìŒ. SegFormerê°€ ImageNet/Cityscapesë¡œ ë°°ì› ìœ¼ë‹ˆê¹Œ\n",
    "    # ëª¨ë¸ì´ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ë°›ì„ ë•Œ: ì…ë ¥_ì´ë¯¸ì§€ = (ì›ë³¸_ì´ë¯¸ì§€ - í‰ê· ) / í‘œì¤€í¸ì°¨\n",
    "    # ì´ë ‡ê²Œ ê³„ì‚°í•´ì£¼ë©´, ì–´ë–¤ ì‚¬ì§„ì´ ë“¤ì–´ì™€ë„ \"í‰ê· ì´ 0ì´ê³  í‘œì¤€í¸ì°¨ê°€ 1ì¸(Standard Normal Distribution)\" ì•„ì£¼ ì˜ˆìœ ë°ì´í„°ë¡œ ë³€ì‹ \n",
    "    # ì „ì²´ ì•¼ê°„ ë°ì´í„°ì…‹ì˜ Mean/Stdë¥¼ ì§ì ‘ ê³„ì‚°í•œ ê°’\n",
    "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "coco = COCO(JSON_PATH)\n",
    "img_ids = list(coco.imgs.keys())\n",
    "cat_ids = coco.getCatIds()\n",
    "id_to_idx = {cat_id: i for i, cat_id in enumerate(cat_ids)}\n",
    "print(f\"Category Mapping: {id_to_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "PaxYL05itR0D"
   },
   "source": [
    "## Traing / Val ë¶„ë¦¬ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSc3mNS_tRHF",
    "outputId": "47fb854a-41eb-4714-9bd3-7ebbf73847ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.12s)\n",
      "creating index...\n",
      "index created!\n",
      "âœ… Data Ready: Train=160, Val=40\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MotorcycleNightRideDataset(Dataset):\n",
    "    def __init__(self, coco, img_ids, img_dir, id_to_idx, transform=None):\n",
    "        self.coco = coco\n",
    "        self.img_ids = img_ids\n",
    "        self.img_dir = img_dir\n",
    "        self.id_to_idx = id_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        image, mask = process_single_data(self.coco, img_id, self.img_dir, self.id_to_idx, self.transform)\n",
    "        return image, mask\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° ID ë¶„í•  (8:2)\n",
    "coco = COCO(JSON_PATH)\n",
    "all_ids = list(coco.imgs.keys())\n",
    "train_ids, val_ids = train_test_split(all_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Transform ì •ì˜ (ê¸°ì¡´ ì •ì˜ í™œìš© ë° Valìš© ì¶”ê°€)\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG['img_size'][0], CFG['img_size'][1]),\n",
    "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "train_dataset = MotorcycleNightRideDataset(coco, train_ids, IMG_DIR, id_to_idx, train_transform)\n",
    "val_dataset = MotorcycleNightRideDataset(coco, val_ids, IMG_DIR, id_to_idx, val_transform)\n",
    "\n",
    "# 4. ë°ì´í„° ë¡œë” ìƒì„±\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CFG['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=CFG['num_worker'],\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CFG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=CFG['num_worker'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… Data Ready: Train={len(train_ids)}, Val={len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "17ecb67c"
   },
   "source": [
    "### ğŸ“‰ í´ë˜ìŠ¤ë³„ ë¶„í¬ ìš”ì•½ (ë‚´ë¦¼ì°¨ìˆœ)\n",
    "\n",
    "1. **Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)**: **42.9%** (ì••ë„ì  1ìœ„)\n",
    "   - ë°°ê²½(í•˜ëŠ˜, ê±´ë¬¼, í’€ìˆ² ë“±)ì´ ì´ë¯¸ì§€ì˜ ì ˆë°˜ ê°€ê¹Œì´ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "2. **Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)**: **27.1%**\n",
    "   - ë„ë¡œ ìì²´ë„ ê½¤ ë§ì€ ì˜ì—­ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "3. **My bike (ë‚´ ì˜¤í† ë°”ì´)**: **15.8%**\n",
    "   - ì£¼í–‰ì ì‹œì ì´ë¼ ë‚´ ì˜¤í† ë°”ì´ê°€ í•­ìƒ ë³´ì´ê¸° ë•Œë¬¸ì— ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤.\n",
    "4. **Rider (íƒ‘ìŠ¹ì)**: **8.1%**\n",
    "   - ë‹¤ë¥¸ ì˜¤í† ë°”ì´ ìš´ì „ìë‚˜ ë‚´ ì‹ ì²´ê°€ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
    "5. **Moveable (ì´ë™ ë¬¼ì²´)**: **4.7%**\n",
    "   - ë‹¤ë¥¸ ì°¨ëŸ‰, ë³´í–‰ì ë“± ì•ˆì „ì— ê°€ì¥ ì¤‘ìš”í•œ ì¥ì• ë¬¼ì¸ë° ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\n",
    "6. **Lane Mark (ì°¨ì„ )**: **1.4%**\n",
    "   - ê°€ì¥ ì‹¬ê°í•œ ë¶ˆê· í˜•ì…ë‹ˆë‹¤. ë„ë¡œ ì£¼í–‰ì˜ í•µì‹¬ì¸ ì°¨ì„ ì´ ê³ ì‘ 1% ë‚¨ì§“ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471,
     "referenced_widgets": [
      "c769d5b2aa2e409094ca9b8759d59878",
      "2fc4593323a54bd0862fcf085f9274e6",
      "ea1a830623894e6eabbf21b81068fb12",
      "bd4f1f661e6f4493867170d3d10467d3",
      "707a3a3a181b428a9afc41e08821e3a6",
      "1ae5409bf8e143a3bf93cba26842db35",
      "51686477dc9e4e4e9747f3d6deb3b973",
      "dc6e0ac79b4c4b8e8a2414e76e26a01d",
      "7e913f3f41ef499db743e20f49a7806d",
      "ae9e5e3b4398452aba901bf6cc6d785b",
      "66b94080882a4f40b0b45d5bdd92bf9d",
      "0722ecf90228429cb48ff257c31019d0",
      "4bb2e1505f7b48f7844688504bcbf27f",
      "8463b45fff27433195cc69720d82a211",
      "4bd4dec582d747bd8bd36eb802659c35",
      "5d76b397f5204171a87f6199bdb2f2c5",
      "715a11b1946942bd960b232de28e9fb6",
      "ec6ad001af4d4f5d8b0b25da92f993e8",
      "39ef57594bdb4733bda5127d33032fe3",
      "01a7b8b25fd64001bce07ea9fa5c3b22",
      "7eb7a77d94db4ed9bc1779c59fabda55",
      "c940f72e230f48a29a580dd1fcc4b7fd",
      "af1a70aba6f849da907b39bd050bfe21",
      "8373f2b9779c4b5198049d2276972561",
      "def6a1c78a6e459aad4d960d57b85d5a",
      "d31d800bd26a4c26af67b2d5c458c896",
      "450035d2a49d4ffeb459dedd44d47fe5",
      "a89fcf88404d4a6c8f08d731e1435cbc",
      "a31d02bb1cf8476692ac622fd396b9af",
      "cd48a0018be94fe88fe7c131087a7665",
      "4d2b3c4823314818b8f487f10be04ebf",
      "362d6931e3fe4cc3aca150afabd62470",
      "df9edefb936642dbb1de1d02cf1ab77b",
      "c2f74793ca674c16bc4fb569bd3c9540",
      "d743b96cdc154b3f8408f1813feb34be",
      "2fd3990c654c41b3a22892ed31289705",
      "7f86c1e38d99411eb53f2ccf820db1ec",
      "893b98c1c3af407387cd5f9085e3eee0",
      "abf809ed0ec542bbb05c9baaae297054",
      "34452e54c4de4ccdbd559c05548dfac0",
      "15e9394e60c5444694902320034b8912",
      "53ad725ad4524844b798943257460345",
      "514374788cc44dbd804139c7449a18c0",
      "d8a3f9b5583a4c19a68d873361fe0ca8"
     ]
    },
    "id": "model",
    "outputId": "e0bd0c54-4356-4c39-e376-6bb72e291d9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dddb677d2f54800b3193a717595f5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65116057bb94114a11378965234257a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2228fc5fe64b8aa86fea9089caec53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mSegformerForSemanticSegmentation LOAD REPORT\u001b[0m from: nvidia/segformer-b2-finetuned-cityscapes-1024-1024\n",
      "Key                           | Status   |                                                                                                    \n",
      "------------------------------+----------+----------------------------------------------------------------------------------------------------\n",
      "decode_head.classifier.bias   | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19]) vs model:torch.Size([6])                      \n",
      "decode_head.classifier.weight | MISMATCH | Reinit due to size mismatch - ckpt: torch.Size([19, 768, 1, 1]) vs model:torch.Size([6, 768, 1, 1])\n",
      "\n",
      "\u001b[3mNotes:\n",
      "- MISMATCH\u001b[3m\t:ckpt weights were loaded, but they did not match the original empty weight shapes.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259c3281914c463b987bd733d1303519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id2label = {i: coco.loadCats(cat_id)[0]['name'] for cat_id, i in id_to_idx.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    CFG['model_name'],\n",
    "    num_labels=len(id_to_idx),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(CFG['device'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=0.01)\n",
    "\n",
    "# âš–ï¸ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (Class Weights)\n",
    "weights = torch.tensor([\n",
    "    5.0,   # Rider (8.1%) -> ì ë‹¹íˆ ë†’ì„\n",
    "    2.0,   # My bike (15.8%) -> ë‚®ì¶¤ (ì´ë¯¸ ë§ìŒ)\n",
    "    10.0,  # Moveable (4.7%) -> ê°•ë ¥í•˜ê²Œ ë†’ì„\n",
    "    20.0,  # Lane Mark (1.4%) -> ì•„ì£¼ ê°•ë ¥í•˜ê²Œ!! (í•µì‹¬)\n",
    "    1.0,   # Road (27.1%) -> ê¸°ë³¸\n",
    "    0.5    # Undrivable (42.9%) -> ë‚®ì¶¤ (ë„ˆë¬´ ë§ì•„ì„œ ë°©í•´ë¨)\n",
    "], dtype=torch.float).to(CFG['device'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "scaler = GradScaler('cuda') if CFG['device'] == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517,
     "referenced_widgets": [
      "eacd895341274ca083d8ddc1a3879ba4",
      "e35f377246f341738008871078631420",
      "fcb2f2354f2144d4929fc3857b63f00f",
      "70a7f999804b4a008a6d9790a4f39f3a",
      "7a53a9c0e8fe4f599487170344613431",
      "4162fa761b114e70b3db0e6ac5b477dc",
      "a945ecf5247846cc8e3158bae8601127",
      "2ea75b126d1a414cba6807404a86fc1f",
      "a501ab8a0ab14f76b28c83fbfd1d10aa",
      "a51dbb649b514185a751f7d012138fbf",
      "e9bd4700a6ef4cf9b2ff6ed5671ac8a8"
     ]
    },
    "id": "train",
    "outputId": "4e8fc070-2386-4158-8ab7-ccb951632f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ SegFormer-B2 Training Start...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\python_2025\\0.AIFFEL_2025-26\\AIì—”ì§€ë‹ˆì–´_2025.12.29-26.6.26\\6.DLthon\\motor2\\wandb\\run-20260211_225542-gde5jcjc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vlux22-free/LossZero/runs/gde5jcjc' target=\"_blank\">vague-flower-2</a></strong> to <a href='https://wandb.ai/vlux22-free/LossZero' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vlux22-free/LossZero' target=\"_blank\">https://wandb.ai/vlux22-free/LossZero</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vlux22-free/LossZero/runs/gde5jcjc' target=\"_blank\">https://wandb.ai/vlux22-free/LossZero/runs/gde5jcjc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1689e13540ab44949856c3117d41a5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m     upsampled_logits = nn.functional.interpolate(outputs, size=y.shape[-\u001b[32m2\u001b[39m:], mode=\u001b[33m\"\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m\"\u001b[39m, align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     29\u001b[39m     loss = criterion(upsampled_logits, y)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     loss.backward()\n\u001b[32m     31\u001b[39m     optimizer.step()\n\u001b[32m     33\u001b[39m train_loss_sum += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:630\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    622\u001b[39m         Tensor.backward,\n\u001b[32m    623\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         inputs=inputs,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m torch.autograd.backward(\n\u001b[32m    631\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001b[32m    632\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:364\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m _engine_run_backward(\n\u001b[32m    365\u001b[39m     tensors,\n\u001b[32m    366\u001b[39m     grad_tensors_,\n\u001b[32m    367\u001b[39m     retain_graph,\n\u001b[32m    368\u001b[39m     create_graph,\n\u001b[32m    369\u001b[39m     inputs_tuple,\n\u001b[32m    370\u001b[39m     allow_unreachable=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    371\u001b[39m     accumulate_grad=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    372\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:865\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    863\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    866\u001b[39m         t_outputs, *args, **kwargs\n\u001b[32m    867\u001b[39m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ SegFormer-B2 Training Start...\")\n",
    "\n",
    "wandb.init(project=CFG['project'], config=CFG)\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss_sum = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for images, masks in pbar:\n",
    "        X = images.to(CFG['device']).contiguous()\n",
    "        y = masks.to(CFG['device']).contiguous()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision ì§€ì› (CUDA ì „ìš©)\n",
    "        if CFG['device'] == 'cuda' and scaler:\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(X).logits\n",
    "                upsampled_logits = nn.functional.interpolate(outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "                loss = criterion(upsampled_logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(X).logits\n",
    "            upsampled_logits = nn.functional.interpolate(outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = criterion(upsampled_logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss_sum += loss.item()\n",
    "        pbar.set_postfix(Loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    avg_train_loss = train_loss_sum / len(train_loader)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            X = images.to(CFG['device']).contiguous()\n",
    "            y = masks.to(CFG['device']).contiguous()\n",
    "            \n",
    "            outputs = model(X).logits\n",
    "            upsampled_logits = nn.functional.interpolate(outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = criterion(upsampled_logits, y)\n",
    "            val_loss_sum += loss.item()\n",
    "            \n",
    "    avg_val_loss = val_loss_sum / len(val_loader)\n",
    "    wandb.log({'Train Loss': avg_train_loss, 'Val Loss': avg_val_loss, 'epoch': epoch})\n",
    "\n",
    "    print(f\"ğŸ“ Epoch [{epoch+1}/{CFG['epochs']}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e306d8-3ec0-4f85-81bf-7e4544327726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
