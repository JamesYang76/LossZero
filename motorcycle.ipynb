{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "# ğŸï¸ LossZero: Motorcycle Night Ride SegFormer-B2 Optimized\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ **SegFormer-B2** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•¼ê°„ ì˜¤í† ë°”ì´ ì£¼í–‰ ì´ë¯¸ì§€ì˜ ì‹œë©˜í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ğŸ› ï¸ ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤\n",
        "- **ëª¨ë¸**: SegFormer-B2 (Transformer ê¸°ë°˜)\n",
        "- **ë°±ë³¸**: MiT-B2\n",
        "- **ì‚¬ì „ í•™ìŠµ**: Cityscapes (ë„ë¡œ í™˜ê²½ íŠ¹í™”)\n",
        "- **ìµœì í™”**: AdamW + FP16 Mixed Precision\n",
        "- **ì†ì‹¤ í•¨ìˆ˜**: Weighted CrossEntropy (ì¤‘ìš” ê°ì²´ ê°€ì¤‘ì¹˜ ë¶€ì—¬)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1",
        "outputId": "0ca7e713-30b4-4dd8-81c8-0e4a9f379d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pycocotools.coco import COCO\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from transformers import SegformerForSemanticSegmentation, SegformerConfig\n",
        "from torch.amp import autocast, GradScaler\n",
        "from tqdm.auto import tqdm\n",
        "import wandb\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "## Colab ì—°ê²°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "colab-mount",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "colab-mount",
        "outputId": "b12b5d61-075e-4132-c575-818f890c9f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5",
        "outputId": "306aadc9-c650-4208-d4d3-a9f681d4d663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Local Environment\n",
            "Using device: cpu\n",
            "Data directory: /content/drive/MyDrive/data/LossZero/\n"
          ]
        }
      ],
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "\n",
        "    return \"cpu\"\n",
        "\n",
        "def num_worker():\n",
        "    if torch.cuda.is_available():\n",
        "        return os.cpu_count()\n",
        "\n",
        "    return 0\n",
        "\n",
        "# âš™ï¸ ì„¤ì • (Configuration)\n",
        "# DATA_DIR = \"/content/drive/MyDrive/motor_model\"\n",
        "DATA_DIR = \"/content/drive/MyDrive/data/LossZero/\"\n",
        "# DATA_DIR = os.path.expanduser(\"~/Projects/LossZero/data/Motorcycle Night Ride Dataset\")\n",
        "print(\"Detected Local Environment\")\n",
        "\n",
        "JSON_PATH = os.path.join(DATA_DIR, \"COCO_motorcycle (pixel).json\")\n",
        "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
        "\n",
        "CFG = {\n",
        "    \"project\": \"LossZero\",\n",
        "    \"model_name\": \"nvidia/segformer-b2-finetuned-cityscapes-1024-1024\",\n",
        "    \"img_size\": (384, 672),\n",
        "    \"batch_size\": 4,\n",
        "    \"lr\": 1e-4,\n",
        "    \"epochs\": 2,\n",
        "    \"device\": get_device(),\n",
        "    \"num_worker\": num_worker(),\n",
        "    \"train\": True,\n",
        "    \"wndb\": False,\n",
        "}\n",
        "if CFG[\"wndb\"]:\n",
        "    wandb.login()\n",
        "\n",
        "print(f\"Using device: {CFG['device']}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6",
        "outputId": "83902258-dc52-420e-a88c-83b83beffd4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=9.80s)\n",
            "creating index...\n",
            "index created!\n",
            "Category Mapping: {1329681: 0, 1323885: 1, 1323884: 2, 1323882: 3, 1323881: 4, 1323880: 5}\n"
          ]
        }
      ],
      "source": [
        "def create_mask_from_json(coco, img_id, img_info, id_to_idx):\n",
        "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "    anns = coco.loadAnns(ann_ids)\n",
        "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
        "\n",
        "    for ann in anns:\n",
        "        cat_id = ann['category_id']\n",
        "        if cat_id in id_to_idx:\n",
        "            cls_idx = id_to_idx[cat_id]\n",
        "            pixel_mask = coco.annToMask(ann)\n",
        "            mask[pixel_mask == 1] = cls_idx\n",
        "\n",
        "    return mask\n",
        "\n",
        "def process_single_data(coco, img_id, img_dir, id_to_idx, transform=None):\n",
        "    img_info = coco.loadImgs(img_id)[0]\n",
        "    img_path = os.path.join(img_dir, img_info['file_name'])\n",
        "\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    mask = create_mask_from_json(coco, img_id, img_info, id_to_idx)\n",
        "\n",
        "    if transform:\n",
        "        augmented = transform(image=image, mask=mask)\n",
        "        image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "    return image, torch.as_tensor(mask).long()\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    #  ì›ë³¸ í•´ìƒë„ì—ì„œ 480x480 í¬ê¸°ë¡œ ë¬´ì‘ìœ„ ì¶”ì¶œ (í™”ì§ˆ ì €í•˜ ì—†ìŒ)\n",
        "    A.RandomCrop(height=CFG['img_size'][0], width=CFG['img_size'][1], p=1.0),\n",
        "    A.PadIfNeeded(min_height=CFG['img_size'][0], min_width=CFG['img_size'][1], p=1.0),\n",
        "\n",
        "    # --- ì•¼ê°„ ì „ìš© Augmentation ì¶”ê°€ ---\n",
        "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.RandomGamma(gamma_limit=(80, 120), p=0.5), # ì–´ë‘ìš´ ì €ì¡°ë„ ê°œì„ \n",
        "    A.GaussNoise(std_range=(0.02, 0.05), p=0.3), # ì•¼ê°„ ë…¸ì´ì¦ˆ ëŒ€ì‘\n",
        "\n",
        "    # --- ê¸°í•˜í•™ì  ë³€í˜• (ë°ì´í„° ìˆ˜ ë³´ì¶©ìš©) ---\n",
        "    A.HorizontalFlip(p=0.5), # ì¢Œìš° ë°˜ì „\n",
        "    # 0.0625ëŠ” ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì˜¤ë«ë™ì•ˆ ê²€ì¦ëœ 'ì‚¬ì‹¤ìƒ í‘œì¤€(De Facto Standard)\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=25, p=0.5), # ì´ë™/í¬ê¸°/íšŒì „\n",
        "\n",
        "    # ImageNet ë°ì´íƒ€ì…‹ì˜ í‰ê· ê°’ ë‚˜ì˜ì§€ ì•ŠìŒ. SegFormerê°€ ImageNet/Cityscapesë¡œ ë°°ì› ìœ¼ë‹ˆê¹Œ\n",
        "    # ëª¨ë¸ì´ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ë°›ì„ ë•Œ: ì…ë ¥_ì´ë¯¸ì§€ = (ì›ë³¸_ì´ë¯¸ì§€ - í‰ê· ) / í‘œì¤€í¸ì°¨\n",
        "    # ì´ë ‡ê²Œ ê³„ì‚°í•´ì£¼ë©´, ì–´ë–¤ ì‚¬ì§„ì´ ë“¤ì–´ì™€ë„ \"í‰ê· ì´ 0ì´ê³  í‘œì¤€í¸ì°¨ê°€ 1ì¸(Standard Normal Distribution)\" ì•„ì£¼ ì˜ˆìœ ë°ì´í„°ë¡œ ë³€ì‹ \n",
        "    # ì „ì²´ ì•¼ê°„ ë°ì´í„°ì…‹ì˜ Mean/Stdë¥¼ ì§ì ‘ ê³„ì‚°í•œ ê°’\n",
        "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "coco = COCO(JSON_PATH)\n",
        "img_ids = list(coco.imgs.keys())\n",
        "cat_ids = coco.getCatIds()\n",
        "id_to_idx = {cat_id: i for i, cat_id in enumerate(cat_ids)}\n",
        "print(f\"Category Mapping: {id_to_idx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "source": [
        "## Traing / Val ë¶„ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8",
        "outputId": "c98cdab5-d91d-4c74-f7b9-430d0bf7426f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=9.68s)\n",
            "creating index...\n",
            "index created!\n",
            "âœ… Data Ready with Copy-Paste Augmentation!\n",
            "   Train=140 (CP Active), Val=40, Test=20\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "class MotorcycleNightRideDataset(Dataset):\n",
        "    def __init__(self, coco, img_ids, img_dir, id_to_idx, transform=None, use_copy_paste=False):\n",
        "        self.coco = coco\n",
        "        self.img_ids = img_ids\n",
        "        self.img_dir = img_dir\n",
        "        self.id_to_idx = id_to_idx\n",
        "        self.transform = transform\n",
        "        self.use_copy_paste = use_copy_paste  # Copy-Paste í™œì„±í™” ì—¬ë¶€ (Trainë§Œ True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)\n",
        "\n",
        "    def load_image_mask(self, idx):\n",
        "        \"\"\"ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ë¡œë“œí•˜ê³  BGR->RGB ë³€í™˜\"\"\"\n",
        "        img_id = self.img_ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ë§ˆìŠ¤í¬ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ í™œìš©)\n",
        "        mask = create_mask_from_json(self.coco, img_id, img_info, self.id_to_idx)\n",
        "        return image, mask\n",
        "\n",
        "    def apply_copy_paste(self, image, mask):\n",
        "        \"\"\"\n",
        "        Copy-Paste Augmentation:\n",
        "        ë‹¤ë¥¸ ì´ë¯¸ì§€(Donor)ì—ì„œ 'Lane Mark(3)'ë‚˜ 'Moveable(2)' ê°™ì€ ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ ì˜¤ë ¤ë‚´ì–´\n",
        "        í˜„ì¬ ì´ë¯¸ì§€(Target)ì— ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤.\n",
        "        \"\"\"\n",
        "        # 1. ê¸°ì¦ì(Donor) ë¬´ì‘ìœ„ ì„ íƒ\n",
        "        donor_idx = random.randint(0, len(self.img_ids) - 1)\n",
        "        donor_img, donor_mask = self.load_image_mask(donor_idx)\n",
        "\n",
        "        # 2. ì˜¤ë ¤ë‚¼ íƒ€ê²Ÿ í´ë˜ìŠ¤ ì •ì˜ (ì°¨ì„ ê³¼ ì›€ì§ì´ëŠ” ë¬¼ì²´ ì§‘ì¤‘ ê³µëµ)\n",
        "        # Lane Mark: 3, Moveable: 2\n",
        "        target_indices = [2, 3]\n",
        "\n",
        "        # donor_maskì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì¸ í”½ì…€ë§Œ True (ë‚˜ë¨¸ì§€ False)\n",
        "        # np.isinì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬\n",
        "        paste_mask = np.isin(donor_mask, target_indices)\n",
        "\n",
        "        # 3. ë¶™ì—¬ë„£ê¸° (Paste)\n",
        "        # í•´ë‹¹ ì˜ì—­ì— ë‚´ìš©ë¬¼ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì‹¤í–‰\n",
        "        if np.any(paste_mask):\n",
        "            # ì´ë¯¸ì§€ ë®ì–´ì“°ê¸°\n",
        "            image[paste_mask] = donor_img[paste_mask]\n",
        "            # ë§ˆìŠ¤í¬ ë®ì–´ì“°ê¸° (ì •ë‹µì§€ ìˆ˜ì •)\n",
        "            mask[paste_mask] = donor_mask[paste_mask]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ\n",
        "        image, mask = self.load_image_mask(idx)\n",
        "\n",
        "        # 2. Copy-Paste ì ìš© (í›ˆë ¨ ë°ì´í„°ì…‹ì´ê³ , 50% í™•ë¥  ë‹¹ì²¨ ì‹œ)\n",
        "        if self.use_copy_paste and random.random() < 0.5:\n",
        "            image, mask = self.apply_copy_paste(image, mask)\n",
        "\n",
        "        # 3. Albumentations ë³€í™˜ (Resize, ColorJitter, Normalization ë“±)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        return image, torch.as_tensor(mask).long()\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# 1. ë°ì´í„° ë¡œë“œ ë° ID ë¶„í•  (7:2:1)\n",
        "coco = COCO(JSON_PATH)\n",
        "all_ids = list(coco.imgs.keys())\n",
        "\n",
        "# First split: 70% train, 30% temp\n",
        "train_ids, temp_ids = train_test_split(all_ids, test_size=0.3, random_state=42)\n",
        "# Second split: temp_ids into 2/3 for val (0.2 of total), 1/3 for test (0.1 of total)\n",
        "val_ids, test_ids = train_test_split(temp_ids, test_size=1/3, random_state=42)\n",
        "\n",
        "# 2. Transform ì •ì˜ (ê¸°ì¡´ ì •ì˜ í™œìš©)\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(CFG['img_size'][0], CFG['img_size'][1]),\n",
        "    A.Normalize(mean=(0.281, 0.268, 0.346), std=(0.347, 0.290, 0.292)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "# Test transform is the same as validation transform\n",
        "test_transform = val_transform\n",
        "\n",
        "# 3. ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (â˜…Trainì—ë§Œ Copy-Paste í™œì„±í™”â˜…)\n",
        "train_dataset = MotorcycleNightRideDataset(\n",
        "    coco, train_ids, IMG_DIR, id_to_idx,\n",
        "    transform=train_transform,\n",
        "    use_copy_paste=True  # Copy-Paste ON!\n",
        ")\n",
        "val_dataset = MotorcycleNightRideDataset(\n",
        "    coco, val_ids, IMG_DIR, id_to_idx,\n",
        "    transform=val_transform,\n",
        "    use_copy_paste=False # Valì—ëŠ” ì ˆëŒ€ ì“°ë©´ ì•ˆ ë¨ (ìˆœìˆ˜ í‰ê°€)\n",
        ")\n",
        "test_dataset = MotorcycleNightRideDataset( # New test dataset\n",
        "    coco, test_ids, IMG_DIR, id_to_idx,\n",
        "    transform=test_transform,\n",
        "    use_copy_paste=False # Testì—ëŠ” ì ˆëŒ€ ì“°ë©´ ì•ˆ ë¨ (ìˆœìˆ˜ í‰ê°€)\n",
        ")\n",
        "\n",
        "# 4. ë°ì´í„° ë¡œë” ìƒì„±\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=CFG['num_worker'],\n",
        "    pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=CFG['num_worker'],\n",
        "    pin_memory=True\n",
        ")\n",
        "test_loader = DataLoader( # New test loader\n",
        "    test_dataset,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=CFG['num_worker'],\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Define CFG_EVAL for later use\n",
        "CFG_EVAL = {\n",
        "    \"num_classes\": len(id_to_idx)\n",
        "}\n",
        "\n",
        "print(f\"âœ… Data Ready with Copy-Paste Augmentation!\")\n",
        "print(f\"   Train={len(train_ids)} (CP Active), Val={len(val_ids)}, Test={len(test_ids)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "source": [
        "### ğŸ“‰ í´ë˜ìŠ¤ë³„ ë¶„í¬ ìš”ì•½ (ë‚´ë¦¼ì°¨ìˆœ)\n",
        "\n",
        "1. **Undrivable (ì£¼í–‰ ë¶ˆê°€ ì˜ì—­)**: **42.9%** (ì••ë„ì  1ìœ„)\n",
        "   - ë°°ê²½(í•˜ëŠ˜, ê±´ë¬¼, í’€ìˆ² ë“±)ì´ ì´ë¯¸ì§€ì˜ ì ˆë°˜ ê°€ê¹Œì´ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
        "2. **Road (ì£¼í–‰ ê°€ëŠ¥ ë„ë¡œ)**: **27.1%**\n",
        "   - ë„ë¡œ ìì²´ë„ ê½¤ ë§ì€ ì˜ì—­ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
        "3. **My bike (ë‚´ ì˜¤í† ë°”ì´)**: **15.8%**\n",
        "   - ì£¼í–‰ì ì‹œì ì´ë¼ ë‚´ ì˜¤í† ë°”ì´ê°€ í•­ìƒ ë³´ì´ê¸° ë•Œë¬¸ì— ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤.\n",
        "4. **Rider (íƒ‘ìŠ¹ì)**: **8.1%**\n",
        "   - ë‹¤ë¥¸ ì˜¤í† ë°”ì´ ìš´ì „ìë‚˜ ë‚´ ì‹ ì²´ê°€ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
        "5. **Moveable (ì´ë™ ë¬¼ì²´)**: **4.7%**\n",
        "   - ë‹¤ë¥¸ ì°¨ëŸ‰, ë³´í–‰ì ë“± ì•ˆì „ì— ê°€ì¥ ì¤‘ìš”í•œ ì¥ì• ë¬¼ì¸ë° ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\n",
        "6. **Lane Mark (ì°¨ì„ )**: **1.4%**\n",
        "   - ê°€ì¥ ì‹¬ê°í•œ ë¶ˆê· í˜•ì…ë‹ˆë‹¤. ë„ë¡œ ì£¼í–‰ì˜ í•µì‹¬ì¸ ì°¨ì„ ì´ ê³ ì‘ 1% ë‚¨ì§“ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "5eceb0886cf5448cba06c3e6e87eee95",
            "f4ec0b3fa3fb452681d19dbcb048a9db",
            "0acb3049789948e389e2b1306ecb28a8",
            "b7ea9287276c435191672d761063c45e",
            "4bdf1d69e1a049c1b3c8870e774b7877",
            "a557b506710e46bfb0b0de7bf76c0bb0",
            "d506478c440f4dc8b85523d2cccaa9ed",
            "4d5227ca01104462b9bcb67384f0d970",
            "f4738b2b8b894554af68d65ceb1d26a1",
            "416f7738a4174696858325c21edb0cdf",
            "25f6a20dccd14d1bbc4c4177969cfd65"
          ]
        },
        "id": "10",
        "outputId": "126377cf-38f6-4145-f626-dd1fa91fb6d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/380 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5eceb0886cf5448cba06c3e6e87eee95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SegformerForSemanticSegmentation LOAD REPORT from: nvidia/segformer-b2-finetuned-cityscapes-1024-1024\n",
            "Key                           | Status   |                                                                                                  \n",
            "------------------------------+----------+--------------------------------------------------------------------------------------------------\n",
            "decode_head.classifier.weight | MISMATCH | Reinit due to size mismatch ckpt: torch.Size([19, 768, 1, 1]) vs model:torch.Size([6, 768, 1, 1])\n",
            "decode_head.classifier.bias   | MISMATCH | Reinit due to size mismatch ckpt: torch.Size([19]) vs model:torch.Size([6])                      \n",
            "\n",
            "Notes:\n",
            "- MISMATCH\t:ckpt weights were loaded, but they did not match the original empty weight shapes.\n"
          ]
        }
      ],
      "source": [
        "id2label = {i: coco.loadCats(cat_id)[0]['name'] for cat_id, i in id_to_idx.items()}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    CFG['model_name'],\n",
        "    num_labels=len(id_to_idx),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(CFG['device'])\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=CFG['lr'], # Learning Rate\n",
        "    weight_decay=0.05 #ê°€ì¤‘ì¹˜ì˜ ê´€ì„± ì œì–´, ì˜µí‹°ë§ˆì´ì €ì—ì„œ 0.01ì´ë¼ëŠ” ê°’ì€ ë§¤ í•™ìŠµ ë‹¨ê³„(Step)ë§ˆë‹¤ í˜„ì¬ ê°€ì¤‘ì¹˜ ê°’ì„ ì–¼ë§ˆë‚˜ ê¹ì„ì§€ë¥¼ ê²°ì •í•˜ëŠ” ë¹„ìœ¨ì…ë‹ˆë‹¤.\n",
        ")\n",
        "\n",
        "# âš–ï¸ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (Class Weights)\n",
        "weights = torch.tensor([\n",
        "    3.0,   # Rider: 5.0 â†’ 3.0 (ì¤‘ìš”í•˜ì§€ë§Œ ê³¼í•˜ì§€ ì•Šê²Œ)\n",
        "    1.5,   # My bike: 2.0 â†’ 1.5 (ë‚´ ì˜¤í† ë°”ì´ëŠ” ë„ˆë¬´ ì˜ ë§íˆë‹ˆ ì¡°ê¸ˆ ë” ë‚®ì¶¤)\n",
        "    6.0,   # Moveable: 10.0 â†’ 6.0 (ì ˆë°˜ìœ¼ë¡œ ì¤„ì—¬ì„œ ë¶€ë‹´ ì™„í™”)\n",
        "    12.0,  # Lane Mark: 20.0 â†’ 12 (ì—¬ì „íˆ ì œì¼ ê°•ë ¥í•˜ì§€ë§Œ, 20ë°°ëŠ” ë„ˆë¬´ ê°€í˜¹í–ˆìŒ)\n",
        "    1.0,   # Road: 1.0 (ê¸°ì¤€ì  ìœ ì§€)\n",
        "    0.8    # Undrivable: 0.5 â†’ 0.8 (ë°°ê²½ì„ ë„ˆë¬´ ë¬´ì‹œí•´ì„œ ë„ë¡œ ê²½ê³„ê°€ ë¬´ë„ˆì§€ëŠ” ê²ƒ ë°©ì§€)\n",
        "], dtype=torch.float).to(CFG['device'])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "scaler = GradScaler('cuda') if CFG['device'] == 'cuda' else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e9c6c7b1",
      "metadata": {
        "id": "e9c6c7b1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# [1] ê¸°ë³¸ IoU ê³„ì‚° ë¡œì§ (Category-specific)\n",
        "def compute_category_iou(preds, targets, num_classes):\n",
        "    preds_flat = preds.flatten().cpu().numpy()\n",
        "    targets_flat = targets.flatten().cpu().numpy()\n",
        "    valid_mask = (targets_flat >= 0) & (targets_flat < num_classes)\n",
        "    preds_flat = preds_flat[valid_mask]\n",
        "    targets_flat = targets_flat[valid_mask]\n",
        "    cm = confusion_matrix(targets_flat, preds_flat, labels=range(num_classes))\n",
        "    intersection = np.diag(cm)\n",
        "    ground_truth_set = cm.sum(axis=1)\n",
        "    predicted_set = cm.sum(axis=0)\n",
        "    union = ground_truth_set + predicted_set - intersection\n",
        "    iou = intersection / (union + 1e-6)\n",
        "    return iou\n",
        "\n",
        "# [2] Boundary IoU ê³„ì‚° ë¡œì§\n",
        "def get_boundary(mask, dilation_pixels=2):\n",
        "    mask = mask.astype(np.uint8)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    eroded = cv2.erode(mask, kernel, iterations=dilation_pixels)\n",
        "    boundary = mask - eroded\n",
        "    return boundary\n",
        "\n",
        "def compute_boundary_iou(preds, targets, num_classes, dilation_pixels=2):\n",
        "    preds_np = preds.cpu().numpy()\n",
        "    targets_np = targets.cpu().numpy()\n",
        "    b_ious = []\n",
        "    for c in range(num_classes):\n",
        "        class_preds = (preds_np == c)\n",
        "        class_targets = (targets_np == c)\n",
        "        ious_per_batch = []\n",
        "        for i in range(preds_np.shape[0]):\n",
        "            gt_boundary = get_boundary(class_targets[i], dilation_pixels)\n",
        "            pred_boundary = get_boundary(class_preds[i], dilation_pixels)\n",
        "            intersection = ((gt_boundary > 0) & (pred_boundary > 0)).sum()\n",
        "            union = ((gt_boundary > 0) | (pred_boundary > 0)).sum()\n",
        "            if union == 0:\n",
        "                ious_per_batch.append(1.0)\n",
        "            else:\n",
        "                ious_per_batch.append(intersection / union)\n",
        "        if not ious_per_batch:\n",
        "            b_ious.append(0.0)\n",
        "        else:\n",
        "            b_ious.append(np.mean(ious_per_batch))\n",
        "    return np.array(b_ious)\n",
        "\n",
        "# [3] í†µí•© í‰ê°€ í•¨ìˆ˜ (Metrics Calculation)\n",
        "def evaluate_metrics(preds, targets, num_classes):\n",
        "    \"\"\"ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µì„ ë°›ì•„ ëª¨ë“  ì§€í‘œ(Category IoU, Boundary IoU)ë¥¼ í•œ ë²ˆì— ê³„ì‚°\"\"\"\n",
        "    cat_iou = compute_category_iou(preds, targets, num_classes)\n",
        "    bound_iou = compute_boundary_iou(preds, targets, num_classes)\n",
        "    return cat_iou, bound_iou\n",
        "\n",
        "# [4] ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥ í•¨ìˆ˜ (Report Generation)\n",
        "def print_evaluation_report(avg_cat_iou, avg_bound_iou, id2label=None):\n",
        "    \"\"\"ê³„ì‚°ëœ í‰ê·  IoU ê°’ë“¤ì„ ë°›ì•„ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\"\"\"\n",
        "    print(\"\\n[Validation Report]\")\n",
        "    print(\"  Category-specific IoU:\")\n",
        "    for i, iou in enumerate(avg_cat_iou):\n",
        "        label = id2label[i] if id2label else f\"Class {i}\"\n",
        "        print(f\"    - {label}: {iou:.4f}\")\n",
        "\n",
        "    print(\"\\n  Boundary IoU (Details):\")\n",
        "    for i, iou in enumerate(avg_bound_iou):\n",
        "        label = id2label[i] if id2label else f\"Class {i}\"\n",
        "        print(f\"    - {label}: {iou:.4f}\")\n",
        "\n",
        "    mIoU = np.nanmean(avg_cat_iou)\n",
        "    mBoU = np.nanmean(avg_bound_iou)\n",
        "    print(f\"\\n  --> mIoU: {mIoU:.4f} | mBoU: {mBoU:.4f}\\n\")\n",
        "    return mIoU, mBoU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "outputs": [],
      "source": [
        "# [ê³µí†µ ë¡œì§] ë°ì´í„° ì „ì†¡, ì¶”ë¡ , í™•ëŒ€, ì†ì‹¤ ê³„ì‚°\n",
        "def forward_step(model, images, masks, criterion, device):\n",
        "    # ë°ì´í„°ë¥¼ GPU(CUDA) ë˜ëŠ” CPU ì¤‘ ì‹¤ì œ ì—°ì‚°ì´ ì¼ì–´ë‚  ì¥ì¹˜ë¡œ ë³´ë‚¸ë‹¤\n",
        "    # torch.Tensor í˜•íƒœì´ë©° contiguous()ë¡œ ë©”ëª¨ë¦¬ë¥¼ ì •ë ¬í•œë‹¤\n",
        "    X = images.to(device).contiguous()\n",
        "    y = masks.to(device).contiguous()\n",
        "\n",
        "    # Forward Pass\n",
        "    # logits: ìš°ë¦¬ê°€ ì°¾ëŠ” í´ë˜ìŠ¤ë³„ ì ìˆ˜íŒ (í•„ìˆ˜!) -10.5ë‚˜ 15.2 ê°™ì€ ììœ ë¡œìš´ ìˆ«ì\n",
        "    outputs = model(X).logits\n",
        "\n",
        "    # í™•ëŒ€ (Interpolation)\n",
        "    # ëª¨ë¸ ê²°ê³¼ë¬¼(outputs)ì€ ì—°ì‚° íš¨ìœ¨ì„ ìœ„í•´ 96x96ìœ¼ë¡œ ì¶•ì†Œë˜ì–´ ìˆìŒ\n",
        "    # ì´ë¥¼ ì •ë‹µì§€ yì™€ ë˜‘ê°™ì€ í¬ê¸°(384x384)ë¡œ ë¶€ë“œëŸ½ê²Œ í™•ëŒ€(Interpolate)\n",
        "    # y.shape[-2:] -> (384, 384)\n",
        "    upsampled_logits = nn.functional.interpolate(\n",
        "        outputs, size=y.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "    )\n",
        "\n",
        "    # ì˜¤ì°¨(Loss) ê³„ì‚°\n",
        "    loss = criterion(upsampled_logits, y)\n",
        "\n",
        "    return loss, upsampled_logits, y\n",
        "\n",
        "# [í•™ìŠµ ë‹¨ê³„] í•œ ì—í­ ë™ì•ˆì˜ í•™ìŠµ ì§‘í–‰\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device, scaler=None, epoch=0):\n",
        "    model.train()\n",
        "    train_loss_sum = 0\n",
        "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
        "\n",
        "    for images, masks in pbar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed Precision ì§€ì› (CUDA ì „ìš©)\n",
        "        if device == 'cuda' and scaler:\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                loss, _, _ = forward_step(model, images, masks, criterion, device)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "            loss, _, _ = forward_step(model, images, masks, criterion, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’ê³¼ ì •ë‹µ ì‚¬ì´ì˜ ê±°ë¦¬ ê¸°ë¡\n",
        "        train_loss_sum += loss.item()\n",
        "        pbar.set_postfix(Loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    return train_loss_sum / len(loader)\n",
        "\n",
        "# [ê²€ì¦ ë‹¨ê³„] ëª¨ë“ˆí™”ëœ í‰ê°€ ë¡œì§ ì ìš©\n",
        "def validate(model, loader, criterion, device, num_classes=6, id2label=None):\n",
        "    model.eval()\n",
        "    val_loss_sum = 0\n",
        "\n",
        "    # ì§€í‘œ ëˆ„ì ìš© ë°°ì—´ (Total Accumulators)\n",
        "    total_cat_ious = np.zeros(num_classes)\n",
        "    total_bound_ious = np.zeros(num_classes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in loader:\n",
        "            # 1. ê³µí†µ ë¡œì§ ì‹¤í–‰ (Loss ê³„ì‚°)\n",
        "            loss, logits, y = forward_step(model, images, masks, criterion, device)\n",
        "            val_loss_sum += loss.item()\n",
        "\n",
        "            # 2. ì˜ˆì¸¡ê°’ ë³€í™˜\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # 3. í†µí•© í‰ê°€ ëª¨ë“ˆ í˜¸ì¶œ\n",
        "            cat_iou, bound_iou = evaluate_metrics(preds, y, num_classes)\n",
        "            total_cat_ious += cat_iou\n",
        "            total_bound_ious += bound_iou\n",
        "\n",
        "    # ì—í­ í‰ê·  ê³„ì‚°\n",
        "    avg_loss = val_loss_sum / len(loader)\n",
        "    avg_cat_iou = total_cat_ious / len(loader)\n",
        "    avg_bound_iou = total_bound_ious / len(loader)\n",
        "\n",
        "    # 4. ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥ ëª¨ë“ˆ í˜¸ì¶œ\n",
        "    mIoU, mBoU = print_evaluation_report(avg_cat_iou, avg_bound_iou, id2label)\n",
        "\n",
        "    return avg_loss, mIoU, mBoU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "211691b1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f622d879e0464ee782554fd7e7d99137",
            "a19adb8c551b4082a3ec6461a1999c83",
            "c63c1d2b141b47bd86cdc03044cef8a5",
            "6b06e9315cba4e4b9f0bd23bb9e9ca78",
            "ae2016610219435abaadcbbcaca00311",
            "cfd974ea63b2452dbd445f2f75402bca",
            "66ef96f4f19b4e59a729c60cecca6d61",
            "fff4fac9bb7247609feaa36ac6b2f173",
            "9d2fba70ba77417fbd9fdb005ab1e23e",
            "16c63c1c21824639ab905843b1c394c0",
            "275e952fbeb64d5e95a34a412e319055"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "211691b1",
        "outputId": "f8a3af0e-a6be-4d5b-ff61-2a45d6bed3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ SegFormer-B2 Training Start with Dual Auto-Save Strategy...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1 [Train]:   0%|          | 0/35 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f622d879e0464ee782554fd7e7d99137"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- ğŸš€ ë©”ì¸ í•™ìŠµ ë£¨í”„ (Auto-Save ê¸°ëŠ¥ íƒ‘ì¬) ---\n",
        "print(\"ğŸš€ SegFormer-B2 Training Start with Dual Auto-Save Strategy...\")\n",
        "\n",
        "if CFG[\"wndb\"]:\n",
        "    wandb.init(project=CFG['project'], config=CFG)\n",
        "\n",
        "best_miou = 0.0\n",
        "best_mbou = 0.0\n",
        "best_miou_epoch = 0\n",
        "\n",
        "save_dir = \"./checkpoints\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(CFG['epochs']):\n",
        "    # 1. í•™ìŠµ ì‹¤í–‰\n",
        "    avg_train_loss = train_one_epoch(model, train_loader, optimizer, criterion, CFG['device'], scaler, epoch)\n",
        "\n",
        "    # 2. ê²€ì¦ ì‹¤í–‰\n",
        "    avg_val_loss, avg_val_miou, avg_val_mbou = validate(model, val_loader, criterion, CFG['device'], num_classes=6, id2label=id2label)\n",
        "\n",
        "    wandb.log({'Train Loss': avg_train_loss, 'Val Loss': avg_val_loss, 'epoch': epoch})\n",
        "\n",
        "\n",
        "    print(f\"ğŸ“ Epoch [{epoch+1}/{CFG['epochs']}]\")\n",
        "    print(f\"   Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"   âœ¨ Val mIoU: {avg_val_miou:.4f} | mBoU: {avg_val_mbou:.4f}\")\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # ğŸ’¾ 3. ì´ì¤‘ ìë™ ì €ì¥ (Dual Auto-Save)\n",
        "    # --------------------------------------------------------------------------\n",
        "    # [ê¸°ì¤€ 1] mIoU ì±”í”¼ì–¸ (ê°€ì¥ ë˜‘ë˜‘í•œ ëª¨ë¸)\n",
        "    if avg_val_miou > best_miou:\n",
        "        print(f\"   ğŸ† New Best mIoU! ({best_miou:.4f} -> {avg_val_miou:.4f}) Saving...\")\n",
        "        best_miou = avg_val_miou\n",
        "        best_miou_epoch = epoch + 1\n",
        "        torch.save(model.state_dict(), os.path.join(save_dir, \"segformer_best_miou.pth\"))\n",
        "\n",
        "    # [ê¸°ì¤€ 2] mBoU ì±”í”¼ì–¸ (í…Œë‘ë¦¬ ì¥ì¸)\n",
        "    if avg_val_mbou > best_mbou:\n",
        "        print(f\"   ğŸ¨ New Best mBoU! ({best_mbou:.4f} -> {avg_val_mbou:.4f}) Saving...\")\n",
        "        best_mbou = avg_val_mbou\n",
        "        torch.save(model.state_dict(), os.path.join(save_dir, \"segformer_best_mbou.pth\"))\n",
        "\n",
        "    # 0.5 ìˆ˜ì¤€: \"ê¸°ë°˜ì€ ë‹¦ì•˜ìœ¼ë‚˜, ê³ ë“ì  ë¬¸ì œëŠ” í¬ê¸°í•œ ìƒíƒœ\"\n",
        "    # 0.1 ìˆ˜ì¤€: \"ì‹¤ì „ì— íˆ¬ì…í•´ë³¼ ë§Œí•œ ìš°ë“±ìƒ\"\n",
        "    # 0.01 ìˆ˜ì¤€: \"ì™„ë²½, í˜¹ì€ ë„ˆë¬´ ê³¼í•œ ê³µë¶€(ê³¼ì í•©)\"\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(f\"\\nğŸ‰ Training Complete!\")\n",
        "print(f\"   ğŸ‘‘ Overall Best mIoU: {best_miou:.4f} (at Epoch {best_miou_epoch})\")\n",
        "print(f\"   ğŸ–Œï¸ Overall Best mBoU: {best_mbou:.4f}\")\n",
        "# ë§ˆì§€ë§‰ ìƒíƒœë„ ì €ì¥\n",
        "torch.save(model.state_dict(), os.path.join(save_dir, \"segformer_last.pth\"))\n",
        "\n",
        "if CFG[\"wndb\"]:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71022e54",
      "metadata": {
        "id": "71022e54"
      },
      "source": [
        "### ğŸ› ï¸ ì£¼ìš” í‰ê°€ í•­ëª©\n",
        "- **mIoU** (Mean Intersection over Union):\n",
        "  - **Category-specific IoU**\n",
        "  - **Boundary IoU**\n",
        "- **ì‹¤ì‹œê°„ì„± ë° í•˜ë“œì›¨ì–´ ì§€í‘œ**\n",
        "  - **Model Parameters**\n",
        "  - **MACs** Multiply-Accumulate Operations\n",
        "    - y = wx + b ì—ì„œ wx + bë¥¼ 1MAC ì´ë¼ê³  í•œë‹¤.\n",
        "  - **GFLOPs** Giga Floating Point Operations\n",
        "    -  ëª¨ë¸ì„ í•œ ë²ˆ ì‹¤í–‰(Forward Pass)í•  ë•Œ í•„ìš”í•œ ì´ ë¶€ë™ ì†Œìˆ˜ì  ì—°ì‚°ëŸ‰\n",
        "    - ë³´í†µ 1MAC = 2FLOPs\n",
        "  - **Average Inference Latency**\n",
        "  - **Frames Per Second (FPS)**\n",
        "- **Safety-critical Metrics**\n",
        "\n",
        "- TODO\n",
        "  - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ í‰ê°€í•  ê²ƒ ( í˜„ì¬ëŠ” ì „ì²´ ì´ë¯¸ì§€ SET ì‚¬ìš© )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1934cdc0",
      "metadata": {
        "id": "1934cdc0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from thop import profile\n",
        "\n",
        "def profile_model(model, img_size, device):\n",
        "    print(f\"ğŸš€ Starting Model Profiling for: {model.__class__.__name__}...\")\n",
        "\n",
        "    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "    model.eval()\n",
        "\n",
        "    # 2. ëª¨ë¸ì„ ìœ„í•œ ë”ë¯¸ ì…ë ¥ í…ì„œ ìƒì„±\n",
        "    dummy_input = torch.randn(1, 3, img_size[0], img_size[1]).to(device)\n",
        "\n",
        "    # 3. ë”ë¯¸ ì…ë ¥ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ MACs ë° ë§¤ê°œë³€ìˆ˜(params)ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ thop.profile ì‚¬ìš©. verbose=Falseë¡œ ì„¤ì •.\n",
        "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "\n",
        "    # 4. ê³„ì‚°ëœ MACsë¥¼ 1e9ë¡œ ë‚˜ëˆ„ì–´ GFLOPsë¡œ ë³€í™˜.\n",
        "    gflops = (macs * 2) / 1e9\n",
        "\n",
        "    print(f\"  Model Parameters (M): {params / 1e6:.2f}\")\n",
        "    print(f\"  MACs (G): {macs / 1e9:.2f}\")\n",
        "    print(f\"  GFLOPs: {gflops:.2f}\")\n",
        "\n",
        "    # 5. ì§€ì—° ì‹œê°„ ë° FPS ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”.\n",
        "    num_warmup_runs = 10\n",
        "    num_inference_runs = 100\n",
        "    total_latency = 0.0\n",
        "\n",
        "    # 6. ì›Œë°ì—… ì‹¤í–‰ ìˆ˜í–‰\n",
        "    # print(f\"  Performing {num_warmup_runs} warm-up runs...\")\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_warmup_runs):\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "    # 7. ì¶”ë¡  ì§€ì—° ì‹œê°„ ì¸¡ì •\n",
        "    # print(f\"  Measuring latency over {num_inference_runs} inference runs...\")\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_inference_runs):\n",
        "            start_time = time.perf_counter()\n",
        "            _ = model(dummy_input)\n",
        "            end_time = time.perf_counter()\n",
        "            total_latency += (end_time - start_time)\n",
        "\n",
        "    # 8. í‰ê·  ì§€ì—° ì‹œê°„(ms) ê³„ì‚°\n",
        "    average_latency_ms = (total_latency / num_inference_runs) * 1000\n",
        "\n",
        "    # 9. FPS ê³„ì‚°\n",
        "    fps = 1000 / average_latency_ms\n",
        "\n",
        "    print(f\"  Average Inference Latency: {average_latency_ms:.2f} ms\")\n",
        "    print(f\"  Frames Per Second (FPS): {fps:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cp0ULe5B17zc",
      "metadata": {
        "id": "Cp0ULe5B17zc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "class SafetyEvalMetrics:\n",
        "    def __init__(self, num_classes, class_names):\n",
        "        self.num_classes = num_classes\n",
        "        self.class_names = class_names\n",
        "        self.confusion_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "    def update(self, preds, gts):\n",
        "        \"\"\"\n",
        "        í•œ ë°°ì¹˜(Batch) ë˜ëŠ” í•œ í”„ë ˆì„ì˜ ê²°ê³¼ë¥¼ ëˆ„ì í•©ë‹ˆë‹¤.\n",
        "        preds, gts: [Batch, H, W] í˜•íƒœì˜ Tensor ë˜ëŠ” Numpy\n",
        "        \"\"\"\n",
        "        preds = preds.flatten()\n",
        "        gts = gts.flatten()\n",
        "\n",
        "        # ìœ íš¨í•˜ì§€ ì•Šì€ íƒ€ê²Ÿ ê°’ ì œì™¸ (ì˜ˆ: íŒ¨ë”© ë˜ëŠ” ignore_indexê°€ í¬í•¨ëœ ê²½ìš°)\n",
        "        valid_mask = (gts >= 0) & (gts < self.num_classes)\n",
        "        preds = preds[valid_mask]\n",
        "        gts = gts[valid_mask]\n",
        "\n",
        "        # sklearnì˜ confusion_matrixë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ì—…ë°ì´íŠ¸\n",
        "        # labels ì¸ìë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œê³µí•˜ì—¬ ëª¨ë“  í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ë„ë¡ ë³´ì¥\n",
        "        new_cm = confusion_matrix(gts, preds, labels=range(self.num_classes))\n",
        "        self.confusion_matrix += new_cm\n",
        "\n",
        "    def plot_confusion_matrix(self, normalize=True):\n",
        "        \"\"\"\n",
        "        í˜¼ë™ í–‰ë ¬ ì‹œê°í™”\n",
        "        \"\"\"\n",
        "        cm = self.confusion_matrix\n",
        "        if normalize:\n",
        "            # í–‰(Actual) ê¸°ì¤€ ì •ê·œí™”: í•´ë‹¹ í´ë˜ìŠ¤ê°€ ì‹¤ì œ ë¬´ì—‡ìœ¼ë¡œ ì˜ˆì¸¡ë˜ì—ˆëŠ”ì§€ ë¹„ìœ¨ í™•ì¸\n",
        "            # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ 1e-9 ì¶”ê°€\n",
        "            cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
        "\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.heatmap(cm, annot=True, fmt=\".2f\" if normalize else \"d\",\n",
        "                    cmap=\"Blues\", xticklabels=self.class_names, yticklabels=self.class_names)\n",
        "\n",
        "        plt.title('Road Scene Segmentation: Confusion Matrix')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('Ground Truth Label')\n",
        "        plt.show()\n",
        "\n",
        "    def analyze_safety_risks(self):\n",
        "        \"\"\"\n",
        "        ì¹˜ëª…ì  ì˜¤ë¶„ë¥˜(Safety-Critical) ì§‘ì¤‘ ë¶„ì„\n",
        "        \"\"\"\n",
        "        cm_norm = self.confusion_matrix.astype('float') / (self.confusion_matrix.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
        "\n",
        "        print(\"\\n=== [Safety-Critical Analysis] ===\")\n",
        "\n",
        "        try:\n",
        "            rider_idx = self.class_names.index('Rider')\n",
        "            mybike_idx = self.class_names.index('My bike')\n",
        "            moveable_idx = self.class_names.index('Moveable')\n",
        "            lanemark_idx = self.class_names.index('Lane Mark')\n",
        "            road_idx = self.class_names.index('Road')\n",
        "            undrivable_idx = self.class_names.index('Undrivable')\n",
        "\n",
        "            print(\"--- ê³ ìœ„í—˜ ---\")\n",
        "            undrivable_as_road = cm_norm[undrivable_idx, road_idx]\n",
        "            print(f\"1. ì¦‰ê°ì ì¸ ì¶©ëŒ ìœ„í—˜ - Undrivable -> Roadë¡œ ì˜¤ë¶„ë¥˜ : {undrivable_as_road:.2%}\")\n",
        "\n",
        "            missed_moveable_as_undrivable = cm_norm[moveable_idx, undrivable_idx]\n",
        "            print(f\"2. ì´ë™ ë¬¼ì²´ ì¶©ëŒ ìœ„í—˜ - Moveable -> Undrivableë¡œ ì˜¤ë¶„ë¥˜ : {missed_moveable_as_undrivable:.2%}\")\n",
        "\n",
        "            missed_moveable_as_road = cm_norm[moveable_idx, road_idx]\n",
        "            print(f\"3. ì´ë™ ë¬¼ì²´ ì¶©ëŒ ìœ„í—˜ - Moveable -> Roadë¡œ ì˜¤ë¶„ë¥˜ : {missed_moveable_as_road:.2%}\")\n",
        "\n",
        "            rider_as_undrivable = cm_norm[rider_idx, undrivable_idx]\n",
        "            print(f\"4. ì‹œìŠ¤í…œ ì˜¤ì‘ë™ ìœ ë°œ - Rider -> Undrivableë¡œ ì˜¤ë¶„ë¥˜ : {rider_as_undrivable:.2%}\")\n",
        "\n",
        "            print(\"\\n--- ì¤‘ìœ„í—˜ ---\")\n",
        "            road_to_undrivable = cm_norm[road_idx, undrivable_idx]\n",
        "            print(f\"5. ê²½ë¡œ ê³„íš ì˜¤ë¥˜ - Road -> Undrivable ë¡œ ì˜¤ë¶„ë¥˜ : {road_to_undrivable:.2%}\")\n",
        "\n",
        "            lanemark_as_road = cm_norm[lanemark_idx, road_idx]\n",
        "            print(f\"6. ì°¨ì„  ìœ ì§€ ë³´ì¡° ì˜¤ë¥˜ - Lane Mark -> Roadë¡œ ì˜¤ë¶„ë¥˜ : {lanemark_as_road:.2%}\")\n",
        "\n",
        "            print(\"\\n--- ë‚®ì€-ì¤‘ê°„ ìœ„í—˜ ---\")\n",
        "            rider_as_mybike = cm_norm[rider_idx, mybike_idx]\n",
        "            print(f\"7. ìê¸° ì¸ì‹ ì˜¤ë¥˜ - Rider -> My bikeë¡œ ì˜¤ë¶„ë¥˜ : {rider_as_mybike:.2%}\")\n",
        "\n",
        "        except ValueError as e:\n",
        "            print(f\"ì˜¤ë¥˜: ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "525750d9",
      "metadata": {
        "id": "525750d9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def run_safety_evaluation(model_to_eval, model_name, val_loader, device, num_classes, id2label):\n",
        "    print(f\"ğŸš€ Starting Safety Evaluation for {model_name}...\")\n",
        "\n",
        "    # Instantiate SafetyEvalMetrics\n",
        "    class_names = [name for i, name in sorted(id2label.items())]\n",
        "    evaluator = SafetyEvalMetrics(num_classes=num_classes, class_names=class_names)\n",
        "\n",
        "    # Evaluate the model on the validation set to update the confusion matrix\n",
        "    model_to_eval.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            X = images.to(device).contiguous()\n",
        "            y = masks.to(device).contiguous()\n",
        "\n",
        "            outputs = model_to_eval(X).logits\n",
        "            upsampled_logits = nn.functional.interpolate(\n",
        "                outputs,\n",
        "                size=y.shape[-2:],\n",
        "                mode=\"bilinear\",\n",
        "                align_corners=False\n",
        "            )\n",
        "\n",
        "            preds = upsampled_logits.argmax(dim=1)\n",
        "            evaluator.update(preds.cpu().numpy(), y.cpu().numpy())\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    evaluator.plot_confusion_matrix(normalize=True)\n",
        "    evaluator.analyze_safety_risks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e11d40e5",
      "metadata": {
        "id": "e11d40e5"
      },
      "outputs": [],
      "source": [
        "# Define the path to the saved checkpoints\n",
        "CHECKPOINTS_DIR = \"./checkpoints\"\n",
        "\n",
        "# Recreate the model architecture (it must be the same as during training)\n",
        "# The configuration `CFG['model_name']`, `id2label`, `label2id`, `num_labels` are from previous cells.\n",
        "\n",
        "# Model for Best mIoU\n",
        "model_best_miou = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    CFG['model_name'],\n",
        "    num_labels=len(id_to_idx),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(CFG['device'])\n",
        "\n",
        "# Load the state dictionary for the best mIoU model\n",
        "miou_checkpoint_path = os.path.join(CHECKPOINTS_DIR, \"segformer_best_miou.pth\")\n",
        "model_best_miou.load_state_dict(torch.load(miou_checkpoint_path, map_location=CFG['device']))\n",
        "model_best_miou.eval()\n",
        "\n",
        "# Model for Best mBoU\n",
        "model_best_mbou = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    CFG['model_name'],\n",
        "    num_labels=len(id_to_idx),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(CFG['device'])\n",
        "\n",
        "# Load the state dictionary for the best mBoU model\n",
        "mbou_checkpoint_path = os.path.join(CHECKPOINTS_DIR, \"segformer_best_mbou.pth\")\n",
        "model_best_mbou.load_state_dict(torch.load(mbou_checkpoint_path, map_location=CFG['device']))\n",
        "model_best_mbou.eval()\n",
        "\n",
        "# Call the profiling function for model_best_miou\n",
        "profile_model(model_best_miou, CFG['img_size'], CFG['device'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Call the profiling function for model_best_mbou\n",
        "profile_model(model_best_mbou, CFG['img_size'], CFG['device'])\n",
        "\n",
        "# Run safety evaluation for model_best_miou\n",
        "run_safety_evaluation(\n",
        "    model_best_miou,\n",
        "    \"Best mIoU Model\",\n",
        "    val_loader,\n",
        "    CFG['device'],\n",
        "    CFG_EVAL['num_classes'],\n",
        "    id2label\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Run safety evaluation for model_best_mbou\n",
        "run_safety_evaluation(\n",
        "    model_best_mbou,\n",
        "    \"Best mBoU Model\",\n",
        "    val_loader,\n",
        "    CFG['device'],\n",
        "    CFG_EVAL['num_classes'],\n",
        "    id2label\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5eceb0886cf5448cba06c3e6e87eee95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4ec0b3fa3fb452681d19dbcb048a9db",
              "IPY_MODEL_0acb3049789948e389e2b1306ecb28a8",
              "IPY_MODEL_b7ea9287276c435191672d761063c45e"
            ],
            "layout": "IPY_MODEL_4bdf1d69e1a049c1b3c8870e774b7877"
          }
        },
        "f4ec0b3fa3fb452681d19dbcb048a9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a557b506710e46bfb0b0de7bf76c0bb0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d506478c440f4dc8b85523d2cccaa9ed",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "0acb3049789948e389e2b1306ecb28a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5227ca01104462b9bcb67384f0d970",
            "max": 380,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4738b2b8b894554af68d65ceb1d26a1",
            "value": 380
          }
        },
        "b7ea9287276c435191672d761063c45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_416f7738a4174696858325c21edb0cdf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_25f6a20dccd14d1bbc4c4177969cfd65",
            "value": "â€‡380/380â€‡[00:01&lt;00:00,â€‡230.55it/s,â€‡Materializingâ€‡param=segformer.encoder.patch_embeddings.3.proj.weight]"
          }
        },
        "4bdf1d69e1a049c1b3c8870e774b7877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a557b506710e46bfb0b0de7bf76c0bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d506478c440f4dc8b85523d2cccaa9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d5227ca01104462b9bcb67384f0d970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4738b2b8b894554af68d65ceb1d26a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "416f7738a4174696858325c21edb0cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f6a20dccd14d1bbc4c4177969cfd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f622d879e0464ee782554fd7e7d99137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a19adb8c551b4082a3ec6461a1999c83",
              "IPY_MODEL_c63c1d2b141b47bd86cdc03044cef8a5",
              "IPY_MODEL_6b06e9315cba4e4b9f0bd23bb9e9ca78"
            ],
            "layout": "IPY_MODEL_ae2016610219435abaadcbbcaca00311"
          }
        },
        "a19adb8c551b4082a3ec6461a1999c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd974ea63b2452dbd445f2f75402bca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_66ef96f4f19b4e59a729c60cecca6d61",
            "value": "Epochâ€‡1â€‡[Train]:â€‡â€‡11%"
          }
        },
        "c63c1d2b141b47bd86cdc03044cef8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff4fac9bb7247609feaa36ac6b2f173",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d2fba70ba77417fbd9fdb005ab1e23e",
            "value": 4
          }
        },
        "6b06e9315cba4e4b9f0bd23bb9e9ca78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c63c1c21824639ab905843b1c394c0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_275e952fbeb64d5e95a34a412e319055",
            "value": "â€‡4/35â€‡[03:28&lt;25:33,â€‡49.47s/it,â€‡Loss=1.7721]"
          }
        },
        "ae2016610219435abaadcbbcaca00311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd974ea63b2452dbd445f2f75402bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ef96f4f19b4e59a729c60cecca6d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fff4fac9bb7247609feaa36ac6b2f173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2fba70ba77417fbd9fdb005ab1e23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16c63c1c21824639ab905843b1c394c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "275e952fbeb64d5e95a34a412e319055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}