{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# ğŸï¸ LossZero: Motorcycle Night Ride Semantic Segmentation\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ ì•¼ê°„ ì˜¤í† ë°”ì´ ì£¼í–‰ ì´ë¯¸ì§€ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì¤‘ í´ë˜ìŠ¤ ì‹œë©˜í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.  \n",
                "**Raw ì´ë¯¸ì§€**ì™€ **JSON ì–´ë…¸í…Œì´ì…˜**ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ë©°, W&Bë¥¼ í†µí•´ ì‹¤í—˜ì„ ì¶”ì í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "imports",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/jamesyang/.pyenv/versions/3.12.2/envs/aipel/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch version: 2.10.0\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import cv2\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from pycocotools.coco import COCO\n",
                "import segmentation_models_pytorch as smp\n",
                "import albumentations as A # ë”¥ëŸ¬ë‹ ë¶„ì•¼, íŠ¹íˆ ì„¸ê·¸ë©˜í…Œì´ì…˜(ì‚¬ë¬¼ ê²½ê³„ ë‚˜ëˆ„ê¸°)ì—ì„œ ì„¸ê³„ì ìœ¼ë¡œ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "import wandb\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "f41dc1f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_device():\n",
                "    \"\"\"\n",
                "    ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì ì˜ ì¥ì¹˜(CUDA, MPS, CPU)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
                "    \"\"\"\n",
                "    if torch.cuda.is_available():\n",
                "        return \"cuda\"\n",
                "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
                "        return \"mps\"\n",
                "    return \"cpu\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "config",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data directory: /Users/jamesyang/Projects/LossZero/data/Motorcycle Night Ride Dataset\n",
                        "JSON exists: True\n"
                    ]
                }
            ],
            "source": [
                "# âš™ï¸ ì„¤ì • (Configuration)\n",
                "DATA_DIR = os.path.expanduser(\"~/Projects/LossZero/data/Motorcycle Night Ride Dataset\") \n",
                "JSON_PATH = os.path.join(DATA_DIR, \"COCO_motorcycle (pixel).json\")\n",
                "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
                "\n",
                "CFG = {\n",
                "    \"project\": \"LossZero\",\n",
                "    \"base_model\": \"DeepLabV3Plus\",\n",
                "    \"encoder\": \"resnet34\",\n",
                "    \"img_size\": (512, 512),\n",
                "    \"batch_size\": 8,\n",
                "    \"lr\": 1e-4,\n",
                "    \"epochs\": 50,\n",
                "    \"device\": get_device()\n",
                "}\n",
                "\n",
                "print(f\"Data directory: {DATA_DIR}\")\n",
                "print(f\"JSON exists: {os.path.exists(JSON_PATH)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dataset_desc",
            "metadata": {},
            "source": [
                "### ğŸšœ Dataset í´ë˜ìŠ¤ ì •ì˜ (Raw + JSON â” Mask)\n",
                "JSONì— ì íŒ ë¬¸ìì—´ ì¢Œí‘œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í”½ì…€ ë‹¨ìœ„ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜í•˜ì—¬ ëª¨ë¸ì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dataset_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_mask_from_json(coco, img_id, img_info, id_to_idx):\n",
                "    \"\"\"\n",
                "    JSONì˜ ì¢Œí‘œ ë°ì´í„°ë¥¼ ë³´ê³  ë„í™”ì§€ì— ì •ë‹µ(Mask)ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜\n",
                "    \"\"\"\n",
                "    ann_ids = coco.getAnnIds(imgIds=img_id) #í•´ë‹¹ ì‚¬ì§„ì— ë‹¬ë¦° ì •ë‹µì§€(ì–´ë…¸í…Œì´ì…˜) ë²ˆí˜¸ë¥¼ ëª½ë•… ê°€ì ¸ì™€\n",
                "    anns = coco.loadAnns(ann_ids)\n",
                "    mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
                "    \n",
                "    for ann in anns:\n",
                "        cat_id = ann['category_id']\n",
                "        cls_idx = id_to_idx[cat_id]\n",
                "        pixel_mask = coco.annToMask(ann) # ì¢Œí‘œ -> í”½ì…€ ë§ˆìŠ¤í¬ ë³€í™˜\n",
                "        mask[pixel_mask == 1] = cls_idx   # í•´ë‹¹ ì˜ì—­ì„ í´ë˜ìŠ¤ ë²ˆí˜¸ë¡œ ìƒ‰ì¹ \n",
                "        \n",
                "    return mask\n",
                "\n",
                "def process_single_data(coco, img_id, img_dir, id_to_idx, transform=None):\n",
                "    \"\"\"\n",
                "    ì´ë¯¸ì§€ í•œ ì¥ì„ ì½ê³ , ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ê³ , ì¦ê°•(Augmentation)ê¹Œì§€ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
                "    \"\"\"\n",
                "    # 1. ì •ë³´ ë° ì´ë¯¸ì§€ ë¡œë“œ\n",
                "    img_info = coco.loadImgs(img_id)[0] # ì›ë³¸ ì´ë¯¸ì§€...\n",
                "    img_path = os.path.join(img_dir, img_info['file_name'])\n",
                "    \n",
                "    image = cv2.imread(img_path)\n",
                "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # 2. ë§ˆìŠ¤í¬ ìƒì„± (í•¨ìˆ˜ í˜¸ì¶œ)\n",
                "    mask = create_mask_from_json(coco, img_id, img_info, id_to_idx)\n",
                "    \n",
                "    # 3. ë°ì´í„° ì¦ê°• ë° í…ì„œ ë³€í™˜\n",
                "    if transform:\n",
                "        augmented = transform(image=image, mask=mask)\n",
                "        image, mask = augmented['image'], augmented['mask']\n",
                "    \n",
                "    return image, torch.as_tensor(mask).long()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "c3fa0923",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loading annotations into memory...\n",
                        "Done (t=0.94s)\n",
                        "creating index...\n",
                        "index created!\n",
                        "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200]\n",
                        "{1329681: 0, 1323885: 1, 1323884: 2, 1323882: 3, 1323881: 4, 1323880: 5}\n"
                    ]
                }
            ],
            "source": [
                "# ğŸ–¼ï¸ ë°ì´í„° ì¦ê°• ì„¤ì •\n",
                "train_transform = A.Compose([\n",
                "    A.Resize(CFG['img_size'][0], CFG['img_size'][1]),  # 512, 512\n",
                "    # A.HorizontalFlip(p=0.5), #A.HorizontalFlip(p=0.5) : \"ê±°ìš¸ ëª¨ë“œë¡œ ë³´ì—¬ì£¼ê¸°\" ë°ì´íƒ€ ì¦ê°• 2ë°°\n",
                "    #A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
                "    # ì‚¬ì§„ë§ˆë‹¤ ì¡°ëª…ì´ ë„ˆë¬´ ë°ê±°ë‚˜ ì–´ë‘ìš°ë©´ AIê°€ í•™ìŠµí•˜ê¸° í˜ë“¤ì–´í•©ë‹ˆë‹¤.\n",
                "    # ì—¬ê¸° ì íŒ ìˆ«ìë“¤(mean, std)ì€ ì „ ì„¸ê³„ ìˆ˜ë°±ë§Œ ì¥ì˜ í‘œì¤€ ì‚¬ì§„ë“¤ì˜ í‰ê· ê°’ì…ë‹ˆë‹¤. \n",
                "    # ì´ í•„í„°ë¥¼ í†µê³¼í•˜ë©´ ëª¨ë“  ì‚¬ì§„ì˜ í”½ì…€ ê°’ì´ ìœ ì‚¬í•œ ë²”ìœ„(-1ì—ì„œ 1 ì‚¬ì´ ë“±)ë¡œ ì¬ì¡°ì •ë˜ì–´ í•™ìŠµì´ í›¨ì”¬ ë¹¨ë¼ì§‘ë‹ˆë‹¤.\n",
                "    ToTensorV2() #í…ì„œ ë³€í™˜\n",
                "])\n",
                "# ğŸ› ï¸ COCO ë°ì´í„° ì •ë³´ ë¡œë“œ\n",
                "coco = COCO(JSON_PATH)\n",
                "img_ids = list(coco.imgs.keys()) # ì´ í•¨ìˆ˜ëŠ” ë°ì´í„°ì…‹ì— ë“¤ì–´ìˆëŠ” ëª¨ë“  ì´ë¯¸ì§€ ì‚¬ì§„ì˜ ê³ ìœ  ë²ˆí˜¸(ID)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
                "print(img_ids)\n",
                "id_to_idx = {cat_id: i for i, cat_id in enumerate(coco.getCatIds())} # ì´ í•¨ìˆ˜ëŠ” Category ID\n",
                "print(id_to_idx)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "48779662",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ğŸ—ï¸ ëª¨ë¸ ë° ì†ì‹¤í•¨ìˆ˜ ì„¤ì •\n",
                "model = smp.DeepLabV3Plus(\n",
                "    encoder_name=CFG['encoder'],   # resnet34\n",
                "    encoder_weights=\"imagenet\",    # ì´ë¯¸ ê³µë¶€ê°€ ì¢€ ëœ ë°±ë³¸ ì‚¬ìš©\n",
                "    in_channels=3,                 # RGB ì»¬ëŸ¬ ì´ë¯¸ì§€\n",
                "    classes=len(coco.getCatIds())  # ë¶„ë¥˜í•  ì‚¬ë¬¼ ê°œìˆ˜\n",
                ").to(CFG['device'])                # GPU/MPS/CPU ì¥ì¹˜ë¡œ ì „ì†¡\n",
                "\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr']) # ê³µë¶€ë²•\n",
                "criterion = smp.losses.DiceLoss(mode='multiclass')             # ì±„ì  ë°©ì‹(ê²½ê³„ì„  ìœ„ì£¼)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "dbaa8e6e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch [1/50] Avg Loss: 0.7035\n",
                        "Epoch [2/50] Avg Loss: 0.4594\n",
                        "Epoch [3/50] Avg Loss: 0.3421\n",
                        "Epoch [4/50] Avg Loss: 0.2925\n",
                        "Epoch [5/50] Avg Loss: 0.2475\n",
                        "Epoch [6/50] Avg Loss: 0.2178\n",
                        "Epoch [7/50] Avg Loss: 0.1939\n",
                        "Epoch [8/50] Avg Loss: 0.1725\n",
                        "Epoch [9/50] Avg Loss: 0.1535\n",
                        "Epoch [10/50] Avg Loss: 0.1463\n",
                        "Epoch [11/50] Avg Loss: 0.1311\n",
                        "Epoch [12/50] Avg Loss: 0.1241\n",
                        "Epoch [13/50] Avg Loss: 0.1158\n",
                        "Epoch [14/50] Avg Loss: 0.1089\n",
                        "Epoch [15/50] Avg Loss: 0.1062\n",
                        "Epoch [16/50] Avg Loss: 0.1008\n",
                        "Epoch [17/50] Avg Loss: 0.0949\n",
                        "Epoch [18/50] Avg Loss: 0.0910\n",
                        "Epoch [19/50] Avg Loss: 0.0897\n",
                        "Epoch [20/50] Avg Loss: 0.0879\n",
                        "Epoch [21/50] Avg Loss: 0.0839\n",
                        "Epoch [22/50] Avg Loss: 0.0842\n",
                        "Epoch [23/50] Avg Loss: 0.0829\n",
                        "Epoch [24/50] Avg Loss: 0.0816\n",
                        "Epoch [25/50] Avg Loss: 0.0772\n",
                        "Epoch [26/50] Avg Loss: 0.0748\n",
                        "Epoch [27/50] Avg Loss: 0.0756\n",
                        "Epoch [28/50] Avg Loss: 0.0759\n",
                        "Epoch [29/50] Avg Loss: 0.0720\n",
                        "Epoch [30/50] Avg Loss: 0.0691\n",
                        "Epoch [31/50] Avg Loss: 0.0678\n",
                        "Epoch [32/50] Avg Loss: 0.0696\n",
                        "Epoch [33/50] Avg Loss: 0.0643\n",
                        "Epoch [34/50] Avg Loss: 0.0717\n",
                        "Epoch [35/50] Avg Loss: 0.0690\n",
                        "Epoch [36/50] Avg Loss: 0.0655\n",
                        "Epoch [37/50] Avg Loss: 0.0616\n",
                        "Epoch [38/50] Avg Loss: 0.0615\n",
                        "Epoch [39/50] Avg Loss: 0.0605\n",
                        "Epoch [40/50] Avg Loss: 0.0604\n",
                        "Epoch [41/50] Avg Loss: 0.0621\n",
                        "Epoch [42/50] Avg Loss: 0.0604\n",
                        "Epoch [43/50] Avg Loss: 0.0612\n",
                        "Epoch [44/50] Avg Loss: 0.0584\n",
                        "Epoch [45/50] Avg Loss: 0.0581\n",
                        "Epoch [46/50] Avg Loss: 0.0570\n",
                        "Epoch [47/50] Avg Loss: 0.0568\n",
                        "Epoch [48/50] Avg Loss: 0.0563\n",
                        "Epoch [49/50] Avg Loss: 0.0550\n",
                        "Epoch [50/50] Avg Loss: 0.0548\n"
                    ]
                }
            ],
            "source": [
                "# ğŸš€ í•™ìŠµ ì‹œì‘ (ìˆœìˆ˜ ë°˜ë³µë¬¸ ë°©ì‹)\n",
                "for epoch in range(CFG['epochs']):\n",
                "    model.train()\n",
                "    np.random.shuffle(img_ids) # ë§¤ë²ˆ ê³µë¶€ ìˆœì„œë¥¼ ë°”ê¿‰ë‹ˆë‹¤.\n",
                "    \n",
                "    epoch_loss = 0\n",
                "    # ë°°ì¹˜ í¬ê¸°(8ì¥)ë§Œí¼ì”© ëŠì–´ì„œ ê³µë¶€í•©ë‹ˆë‹¤.\n",
                "    for i in range(0, len(img_ids), CFG['batch_size']):\n",
                "        batch_ids = img_ids[i : i + CFG['batch_size']]\n",
                "        \n",
                "        # [í•¨ìˆ˜ í˜¸ì¶œ] ì´ë¯¸ì§€ì™€ ì •ë‹µì§€ ì„¸íŠ¸ ë§Œë“¤ê¸°\n",
                "        images, masks = [], []\n",
                "        for img_id in batch_ids:\n",
                "            img, msk = process_single_data(coco, img_id, IMG_DIR, id_to_idx, train_transform)\n",
                "            images.append(img)\n",
                "            masks.append(msk)\n",
                "        \n",
                "        # ë©ì–´ë¦¬ë¡œ ë¬¶ì–´ì„œ ì¥ì¹˜(GPU ë“±)ë¡œ ë³´ëƒ…ë‹ˆë‹¤.\n",
                "        X = torch.stack(images).to(CFG['device']).float() # ì…ë ¥ì‚¬ì§„...\n",
                "        y = torch.stack(masks).to(CFG['device']).long() # ì •ë‹µì§€... ì¢Œí‘œê°’ì´ ì•„ë‹ˆë¼, ì¢Œí‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¸ë ¤ì§„ \"ì •ë‹µ ì§€ë„(Mask)\"ì„.\n",
                "        \n",
                "        # ê³µë¶€ ì§„í–‰\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(X)\n",
                "        loss = criterion(outputs, y)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "        \n",
                "    print(f\"Epoch [{epoch+1}/{CFG['epochs']}] Avg Loss: {epoch_loss/(len(img_ids)//CFG['batch_size']):.4f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "aipel",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
